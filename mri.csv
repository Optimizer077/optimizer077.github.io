"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"WDPDP3Z6","preprint","2024","Lüpke, Sven; Yeganeh, Yousef; Adeli, Ehsan; Navab, Nassir; Farshad, Azade","Physics-Informed Latent Diffusion for Multimodal Brain MRI Synthesis","","","","10.48550/arXiv.2409.13532","http://arxiv.org/abs/2409.13532","Recent advances in generative models for medical imaging have shown promise in representing multiple modalities. However, the variability in modality availability across datasets limits the general applicability of the synthetic data they produce. To address this, we present a novel physics-informed generative model capable of synthesizing a variable number of brain MRI modalities, including those not present in the original dataset. Our approach utilizes latent diffusion models and a two-step generative process: first, unobserved physical tissue property maps are synthesized using a latent diffusion model, and then these maps are combined with a physical signal model to generate the final MRI scan. Our experiments demonstrate the efficacy of this approach in generating unseen MR contrasts and preserving physical plausibility. Furthermore, we validate the distributions of generated tissue properties by comparing them to those measured in real brain tissue.","2024-10-01","2025-04-11 02:10:56","2025-04-11 02:11:28","2025-04-11 02:10:56","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2409.13532 [eess]","","/Users/alihaider/Zotero/storage/GBG5Y3TJ/Lüpke et al. - 2024 - Physics-Informed Latent Diffusion for Multimodal Brain MRI Synthesis.pdf; /Users/alihaider/Zotero/storage/MPP4TQSN/2409.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2409.13532","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITGCCAIZ","journalArticle","2024","Cao, Chentao; Cui, Zhuo-Xu; Wang, Yue; Liu, Shaonan; Chen, Taijin; Zheng, Hairong; Liang, Dong; Zhu, Yanjie","High-Frequency Space Diffusion Models for Accelerated MRI","IEEE Transactions on Medical Imaging","","0278-0062, 1558-254X","10.1109/TMI.2024.3351702","http://arxiv.org/abs/2208.05481","Diffusion models with continuous stochastic differential equations (SDEs) have shown superior performances in image generation. It can serve as a deep generative prior to solving the inverse problem in magnetic resonance (MR) reconstruction. However, low-frequency regions of $k$-space data are typically fully sampled in fast MR imaging, while existing diffusion models are performed throughout the entire image or $k$-space, inevitably introducing uncertainty in the reconstruction of low-frequency regions. Additionally, existing diffusion models often demand substantial iterations to converge, resulting in time-consuming reconstructions. To address these challenges, we propose a novel SDE tailored specifically for MR reconstruction with the diffusion process in high-frequency space (referred to as HFS-SDE). This approach ensures determinism in the fully sampled low-frequency regions and accelerates the sampling procedure of reverse diffusion. Experiments conducted on the publicly available fastMRI dataset demonstrate that the proposed HFS-SDE method outperforms traditional parallel imaging methods, supervised deep learning, and existing diffusion models in terms of reconstruction accuracy and stability. The fast convergence properties are also confirmed through theoretical and experimental validation. Our code and weights are available at https://github.com/Aboriginer/HFS-SDE.","2024-05","2025-04-11 02:12:01","2025-04-11 02:12:01","2025-04-11 02:12:01","1853-1865","","5","43","","IEEE Trans. Med. Imaging","","","","","","","","","","","","","arXiv.org","","arXiv:2208.05481 [eess]","","/Users/alihaider/Zotero/storage/JVGY5RVM/Cao et al. - 2024 - High-Frequency Space Diffusion Models for Accelerated MRI.pdf; /Users/alihaider/Zotero/storage/85GRXNGK/2208.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPSHHE7J","preprint","2024","Cui, Zhuo-Xu; Cao, Chentao; Wang, Yue; Jia, Sen; Cheng, Jing; Liu, Xin; Zheng, Hairong; Liang, Dong; Zhu, Yanjie","SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI","","","","10.48550/arXiv.2304.05060","http://arxiv.org/abs/2304.05060","Diffusion models have emerged as a leading methodology for image generation and have proven successful in the realm of magnetic resonance imaging (MRI) reconstruction. However, existing reconstruction methods based on diffusion models are primarily formulated in the image domain, making the reconstruction quality susceptible to inaccuracies in coil sensitivity maps (CSMs). k-space interpolation methods can effectively address this issue but conventional diffusion models are not readily applicable in k-space interpolation. To overcome this challenge, we introduce a novel approach called SPIRiT-Diffusion, which is a diffusion model for k-space interpolation inspired by the iterative self-consistent SPIRiT method. Specifically, we utilize the iterative solver of the self-consistent term (i.e., k-space physical prior) in SPIRiT to formulate a novel stochastic differential equation (SDE) governing the diffusion process. Subsequently, k-space data can be interpolated by executing the diffusion process. This innovative approach highlights the optimization model's role in designing the SDE in diffusion models, enabling the diffusion process to align closely with the physics inherent in the optimization model, a concept referred to as model-driven diffusion. We evaluated the proposed SPIRiT-Diffusion method using a 3D joint intracranial and carotid vessel wall imaging dataset. The results convincingly demonstrate its superiority over image-domain reconstruction methods, achieving high reconstruction quality even at a substantial acceleration rate of 10.","2024-04-20","2025-04-11 02:14:14","2025-04-11 02:14:14","2025-04-11 02:14:14","","","","","","","SPIRiT-Diffusion","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2304.05060 [cs]","","/Users/alihaider/Zotero/storage/REITHQTL/Cui et al. - 2024 - SPIRiT-Diffusion Self-Consistency Driven Diffusion Model for Accelerated MRI.pdf; /Users/alihaider/Zotero/storage/23L9G73G/2304.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2304.05060","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"23HPC5IE","webpage","","","Exploring the Acceleration Limits of Deep Learning Variational Network–based Two-dimensional Brain MRI","","","","","https://pubs.rsna.org/doi/epdf/10.1148/ryai.210313","","","2025-04-11 02:15:58","2025-04-11 02:15:58","2025-04-11 02:15:58","","","","","","","","","","","","","","en","","","","","","","DOI: 10.1148/ryai.210313","","/Users/alihaider/Zotero/storage/L8IZMRMR/Exploring the Acceleration Limits of Deep Learning Variational Network–based Two-dimensional Brain M.pdf; /Users/alihaider/Zotero/storage/KHF7Y8HN/ryai.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCZ482GD","journalArticle","2022","Chung, Hyungjin","Score-based diffusion models for accelerated MRI","","","","","","Score-based diffusion models provide a powerful way to model images using the gradient of the data distribution. Leveraging the learned score function as a prior, here we introduce a way to sample data from a conditional distribution given the measurements, such that the model can be readily used for solving inverse problems in imaging, especially for accelerated MRI. In short, we train a continuous timedependent score function with denoising score matching. Then, at the inference stage, we iterate between the numerical SDE solver and data consistency step to achieve reconstruction. Our model requires magnitude images only for training, and yet is able to reconstruct complex-valued data, and even extends to parallel imaging. The proposed method is agnostic to sub-sampling patterns and has excellent generalization capability so that it can be used with any sampling schemes for any body parts that are not used for training data. Also, due to its generative nature, our approach can quantify uncertainty, which is not possible with standard regression settings. On top of all the advantages, our method also has very strong performance, even beating the models trained with full supervision. With extensive experiments, we verify the superiority of our method in terms of quality and practicality.","2022","2025-04-11 02:36:00","2025-04-11 02:36:00","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/S69UYQTD/Chung - 2022 - Score-based diffusion models for accelerated MRI.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMVUNJRH","preprint","2023","Huang, Jiahao; Aviles-Rivero, Angelica; Schönlieb, Carola-Bibiane; Yang, Guang","CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling for Fast MRI?","","","","10.48550/arXiv.2306.14350","http://arxiv.org/abs/2306.14350","Deep learning has shown the capability to substantially accelerate MRI reconstruction while acquiring fewer measurements. Recently, diffusion models have gained burgeoning interests as a novel group of deep learning-based generative methods. These methods seek to sample data points that belong to a target distribution from a Gaussian distribution, which has been successfully extended to MRI reconstruction. In this work, we proposed a Cold Diffusion-based MRI reconstruction method called CDiffMR. Different from conventional diffusion models, the degradation operation of our CDiffMR is based on k -space undersampling instead of adding Gaussian noise, and the restoration network is trained to harness a de-aliaseing function. We also design starting point and data consistency conditioning strategies to guide and accelerate the reverse process. More intriguingly, the pre-trained CDiffMR model can be reused for reconstruction tasks with different undersampling rates. We demonstrated, through extensive numerical and visual experiments, that the proposed CDiffMR can achieve comparable or even superior reconstruction results than state-of-the-art models. Compared to the diffusion model-based counterpart, CDiffMR reaches readily competing results using only 1.6 ∼ 3.4% for inference time. The code is publicly available at https://github.com/ayanglab/CDiffMR.","2023-06-25","2025-04-11 02:36:10","2025-04-11 02:36:10","2025-04-11 02:36:10","","","","","","","CDiffMR","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2306.14350 [eess]","","/Users/alihaider/Zotero/storage/VSLMJWQG/Huang et al. - 2023 - CDiffMR Can We Replace the Gaussian Noise with K-Space Undersampling for Fast MRI.pdf","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2306.14350","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UK4MA8R","preprint","2024","Jimenez-Perez, Guillermo; Osorio, Pedro; Cersovsky, Josef; Montalt-Tordera, Javier; Hooge, Jens; Vogler, Steffen; Mohammadi, Sadegh","DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training","","","","10.48550/arXiv.2407.11594","http://arxiv.org/abs/2407.11594","Diffusion models (DMs) have emerged as powerful foundation models for a variety of tasks, with a large focus in synthetic image generation. However, their requirement of large annotated datasets for training limits their applicability in medical imaging, where datasets are typically smaller and sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for training latent diffusion models (LDMs) that conditions the generation process on image embeddings extracted from DiNO. By eliminating the reliance on annotations, our training leverages over 868k unlabelled images from public chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows comprehensive manifold coverage, with FID scores as low as 4.7, and emerging properties when evaluated in downstream tasks. It can be used to generate semantically-diverse synthetic datasets even from small data pools, demonstrating up to 20% AUC increase in classification performance when used for data augmentation. Images were generated with different sampling strategies over the DiNO embedding manifold and using real images as a starting point. Results suggest, DiNO-Diffusion could facilitate the creation of large datasets for flexible training of downstream AI models from limited amount of real data, while also holding potential for privacy preservation. Additionally, DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4% Dice score when evaluating lung lobe segmentation. This evidences good CXR image-anatomy alignment, akin to segmenting using textual descriptors on vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical imaging modalities or state-of-the-art diffusion models, opening the door for large-scale, multi-domain image generation pipelines for medical imaging.","2024-07-16","2025-04-11 02:36:12","2025-04-11 02:36:12","2025-04-11 02:36:12","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2407.11594 [cs]","","/Users/alihaider/Zotero/storage/2VJSQMUS/Jimenez-Perez et al. - 2024 - DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2407.11594","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAAH3YP9","journalArticle","","Cao, Chentao; Cui, Zhuo-Xu; Wang, Yue; Liu, Shaonan; Chen, Taijin; Zheng, Hairong; Zhu, Yanjie","High-Frequency Space Diffusion Model for Accelerated MRI","","","","","","","","2025-04-11 02:36:19","2025-04-11 02:36:19","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/7YVHQ7YW/Cao et al. - High-Frequency Space Diffusion Model for Accelerated MRI.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPIDEGPM","journalArticle","2025","Chu, Jiayue","Highly accelerated MRI via implicit neural representation guided posterior sampling of diffusion models","Medical Image Analysis","","","","","Reconstructing high-fidelity magnetic resonance (MR) images from under-sampled k-space is a commonly used strategy to reduce scan time. The posterior sampling of diffusion models based on the real measurement data holds significant promise of improved reconstruction accuracy. However, traditional posterior sampling methods often lack effective data consistency guidance, leading to inaccurate and unstable reconstructions. Implicit neural representation (INR) has emerged as a powerful paradigm for solving inverse problems by modeling a signal’s attributes as a continuous function of spatial coordinates. In this study, we present a novel posterior sampler for diffusion models using INR, named DiffINR. The INR-based component incorporates both the diffusion prior distribution and the MRI physical model to ensure high data fidelity. DiffINR demonstrates superior performance on in-distribution datasets with remarkable accuracy, even under high acceleration factors (up to R = 12 in single-channel reconstruction). Furthermore, DiffINR exhibits excellent generalizability across various tissue contrasts and anatomical structures with low uncertainty. Overall, DiffINR significantly improves MRI reconstruction in terms of accuracy, generalizability and stability, paving the way for further accelerating MRI acquisition. Notably, our proposed framework can be a generalizable framework to solve inverse problems in other medical imaging tasks.","2025","2025-04-11 02:36:26","2025-04-11 02:36:26","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/7I2AW97C/Chu - 2025 - Highly accelerated MRI via implicit neural representation guided posterior sampling of diffusion mod.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GRR9VRGG","journalArticle","2022","Chung, Hyungjin; Ye, Jong Chul","Score-based diffusion models for accelerated MRI","Medical Image Analysis","","13618415","10.1016/j.media.2022.102479","https://linkinghub.elsevier.com/retrieve/pii/S1361841522001268","Score-based diffusion models provide a powerful way to model images using the gradient of the data distribution. Leveraging the learned score function as a prior, here we introduce a way to sample data from a conditional distribution given the measurements, such that the model can be readily used for solving inverse problems in imaging, especially for accelerated MRI. In short, we train a continuous timedependent score function with denoising score matching. Then, at the inference stage, we iterate between the numerical SDE solver and data consistency step to achieve reconstruction. Our model requires magnitude images only for training, and yet is able to reconstruct complex-valued data, and even extends to parallel imaging. The proposed method is agnostic to sub-sampling patterns and has excellent generalization capability so that it can be used with any sampling schemes for any body parts that are not used for training data. Also, due to its generative nature, our approach can quantify uncertainty, which is not possible with standard regression settings. On top of all the advantages, our method also has very strong performance, even beating the models trained with full supervision. With extensive experiments, we verify the superiority of our method in terms of quality and practicality.","2022-08","2025-04-11 02:36:32","2025-04-11 02:36:32","2025-04-11 02:36:32","102479","","","80","","Medical Image Analysis","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/PCWEBEL8/Chung and Ye - 2022 - Score-based diffusion models for accelerated MRI.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULF7AFE4","preprint","2022","Peng, Cheng; Guo, Pengfei; Zhou, S. Kevin; Patel, Vishal; Chellappa, Rama","Towards performant and reliable undersampled MR reconstruction via diffusion model sampling","","","","10.48550/arXiv.2203.04292","http://arxiv.org/abs/2203.04292","Magnetic Resonance (MR) image reconstruction from undersampled acquisition promises faster scanning time. To this end, current State-of-The-Art (SoTA) approaches leverage deep neural networks and supervised training to learn a recovery model. While these approaches achieve impressive performances, the learned model can be fragile on unseen degradation, e.g. when given a diﬀerent acceleration factor. These methods are also generally deterministic and provide a single solution to an ill-posed problem; as such, it can be diﬃcult for practitioners to understand the reliability of the reconstruction. We introduce DiﬀuseRecon, a novel diﬀusion model-based MR reconstruction method. DiﬀuseRecon guides the generation process based on the observed signals and a pre-trained diﬀusion model, and does not require additional training on speciﬁc acceleration factors. DiﬀuseRecon is stochastic in nature and generates results from a distribution of fully-sampled MR images; as such, it allows us to explicitly visualize diﬀerent potential reconstruction solutions. Lastly, DiﬀuseRecon proposes an accelerated, coarse-to-ﬁne Monte-Carlo sampling scheme to approximate the most likely reconstruction candidate. The proposed DiﬀuseRecon achieves SoTA performances reconstructing from raw acquisition signals in fastMRI and SKM-TEA. Code will be open-sourced at www.github.com/cpeng93/DiffuseRecon.","2022-03-11","2025-04-11 02:36:34","2025-04-11 02:36:34","2025-04-11 02:36:34","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2203.04292 [eess]","","/Users/alihaider/Zotero/storage/GD7A4D46/Peng et al. - 2022 - Towards performant and reliable undersampled MR reconstruction via diffusion model sampling.pdf","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2203.04292","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8W66YE8","journalArticle","","Shen, Guoyao; Li, Mengyu; Farris, Chad W; Anderson, Stephan; Zhang, Xin","MRI through K-space cold diffusion","","","","","","","","2025-04-11 02:36:41","2025-04-11 02:36:41","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/CFDUY5HR/Shen et al. - MRI through K-space cold diffusion.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKDI5H54","preprint","2024","Oh, Youngmin; Kim, Hyung-Il; Kim, Seong Tae; Kim, Jung Uk","MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection","","","","10.48550/arXiv.2407.16448","http://arxiv.org/abs/2407.16448","Monocular 3D object detection is an important challenging task in autonomous driving. Existing methods mainly focus on performing 3D detection in ideal weather conditions, characterized by scenarios with clear and optimal visibility. However, the challenge of autonomous driving requires the ability to handle changes in weather conditions, such as foggy weather, not just clear weather. We introduce MonoWAD, a novel weather-robust monocular 3D object detector with a weatheradaptive diffusion model. It contains two components: (1) the weather codebook to memorize the knowledge of the clear weather and generate a weather-reference feature for any input, and (2) the weather-adaptive diffusion model to enhance the feature representation of the input feature by incorporating a weather-reference feature. This serves an attention role in indicating how much improvement is needed for the input feature according to the weather conditions. To achieve this goal, we introduce a weather-adaptive enhancement loss to enhance the feature representation under both clear and foggy weather conditions. Extensive experiments under various weather conditions demonstrate that MonoWAD achieves weather-robust monocular 3D object detection. The code and dataset are released at https://github.com/VisualAIKHU/MonoWAD.","2024-07-23","2025-04-11 02:36:43","2025-04-11 02:36:43","2025-04-11 02:36:43","","","","","","","MonoWAD","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2407.16448 [cs]","","/Users/alihaider/Zotero/storage/M9MTBGMQ/Oh et al. - 2024 - MonoWAD Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2407.16448","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWYC6AQS","journalArticle","","Shen, Guoyao; Li, Mengyu; Farris, Chad W; Anderson, Stephan; Zhang, Xin","MRI through K-space cold diffusion","","","","","","","","2025-04-11 02:44:07","2025-04-11 02:44:07","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/TJKJBPCX/Shen et al. - MRI through K-space cold diffusion.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7LYDUHK","preprint","2024","Yen, Chen-Yu; Singhal, Raghav; Sharma, Umang; Ranganath, Rajesh; Chopra, Sumit; Pinto, Lerrel","Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction","","","","10.48550/arXiv.2406.04318","http://arxiv.org/abs/2406.04318","Magnetic Resonance (MR) imaging, despite its proven diagnostic utility, remains an inaccessible imaging modality for disease surveillance at the population level. A major factor rendering MR inaccessible is lengthy scan times. An MR scanner collects measurements associated with the underlying anatomy in the Fourier space, also known as the k-space. Creating a high-fidelity image requires collecting large quantities of such measurements, increasing the scan time. Traditionally to accelerate an MR scan, image reconstruction from under-sampled k-space data is the method of choice. However, recent works show the feasibility of bypassing image reconstruction and directly learning to detect disease directly from a sparser learned subset of the k-space measurements. In this work, we propose Adaptive Sampling for MR (ASMR), a sampling method that learns an adaptive policy to sequentially select k-space samples to optimize for target disease detection. On 6 out of 8 pathology classification tasks spanning the Knee, Brain, and Prostate MR scans, ASMR reaches within 2% of the performance of a fully sampled classifier while using only 8% of the k-space, as well as outperforming prior state-of-the-art work in k-space sampling such as EMRT, LOUPE, and DPS.","2024-06-06","2025-04-12 14:13:46","2025-04-12 14:13:46","2025-04-12 14:13:46","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2406.04318 [cs]","","/Users/alihaider/Zotero/storage/AUHIDSBT/Yen et al. - 2024 - Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction.pdf; /Users/alihaider/Zotero/storage/P64XDDS6/2406.html","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2406.04318","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38NASF4E","preprint","2024","Oh, Youngmin; Kim, Hyung-Il; Kim, Seong Tae; Kim, Jung Uk","MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection","","","","10.48550/arXiv.2407.16448","http://arxiv.org/abs/2407.16448","Monocular 3D object detection is an important challenging task in autonomous driving. Existing methods mainly focus on performing 3D detection in ideal weather conditions, characterized by scenarios with clear and optimal visibility. However, the challenge of autonomous driving requires the ability to handle changes in weather conditions, such as foggy weather, not just clear weather. We introduce MonoWAD, a novel weather-robust monocular 3D object detector with a weather-adaptive diffusion model. It contains two components: (1) the weather codebook to memorize the knowledge of the clear weather and generate a weather-reference feature for any input, and (2) the weather-adaptive diffusion model to enhance the feature representation of the input feature by incorporating a weather-reference feature. This serves an attention role in indicating how much improvement is needed for the input feature according to the weather conditions. To achieve this goal, we introduce a weather-adaptive enhancement loss to enhance the feature representation under both clear and foggy weather conditions. Extensive experiments under various weather conditions demonstrate that MonoWAD achieves weather-robust monocular 3D object detection. The code and dataset are released at https://github.com/VisualAIKHU/MonoWAD.","2024-07-23","2025-05-12 05:09:16","2025-05-12 05:09:16","2025-05-12 05:09:16","","","","","","","MonoWAD","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2407.16448 [cs]","","/Users/alihaider/Zotero/storage/EU3YE2BA/Oh et al. - 2024 - MonoWAD Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection.pdf; /Users/alihaider/Zotero/storage/4CPU6HTD/2407.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2407.16448","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"332PFYKA","preprint","2024","Jiang, Yufeng; Shen, Yiqing","M$^4$oE: A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts","","","","10.48550/arXiv.2405.09446","http://arxiv.org/abs/2405.09446","Medical imaging data is inherently heterogeneous across different modalities and clinical centers, posing unique challenges for developing generalizable foundation models. Conventional entails training distinct models per dataset or using a shared encoder with modality-specific decoders. However, these approaches incur heavy computational overheads and suffer from poor scalability. To address these limitations, we propose the Medical Multimodal Mixture of Experts (M$^4$oE) framework, leveraging the SwinUNet architecture. Specifically, M$^4$oE comprises modality-specific experts; each separately initialized to learn features encoding domain knowledge. Subsequently, a gating network is integrated during fine-tuning to modulate each expert's contribution to the collective predictions dynamically. This enhances model interpretability and generalization ability while retaining expertise specialization. Simultaneously, the M$^4$oE architecture amplifies the model's parallel processing capabilities, and it also ensures the model's adaptation to new modalities with ease. Experiments across three modalities reveal that M$^4$oE can achieve 3.45% over STU-Net-L, 5.11% over MED3D, and 11.93% over SAM-Med2D across the MICCAI FLARE22, AMOS2022, and ATLAS2023 datasets. Moreover, M$^4$oE showcases a significant reduction in training duration with 7 hours less while maintaining a parameter count that is only 30% of its compared methods. The code is available at https://github.com/JefferyJiang-YF/M4oE.","2024-05-15","2025-05-27 09:22:04","2025-05-27 09:22:04","2025-05-27 09:22:04","","","","","","","M$^4$oE","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2405.09446 [eess] version: 1","","/Users/alihaider/Zotero/storage/NXNYCPJZ/Jiang and Shen - 2024 - M$^4$oE A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts.pdf; /Users/alihaider/Zotero/storage/2XUBMVJ2/2405.html","","","Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2405.09446","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZMIX9CU","preprint","2025","Wang, Shansong; Safari, Mojtaba; Li, Qiang; Chang, Chih-Wei; Qiu, Richard LJ; Roper, Justin; Yu, David S.; Yang, Xiaofeng","Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging","","","","10.48550/arXiv.2502.14064","http://arxiv.org/abs/2502.14064","Vision foundation models (VFMs) are pre-trained on extensive image datasets to learn general representations for diverse types of data. These models can subsequently be fine-tuned for specific downstream tasks, significantly boosting performance across a broad range of applications. However, existing vision foundation models that claim to be applicable to various clinical tasks are mostly pre-trained on 3D computed tomography (CT), which benefits from the availability of extensive 3D CT databases. Significant differences between CT and magnetic resonance imaging (MRI) in imaging principles, signal characteristics, and data distribution may hinder their practical performance and versatility in MRI-specific applications. Here, we propose Triad, a vision foundation model for 3D MRI. Triad adopts a widely used autoencoder architecture to learn robust representations from 131,170 3D MRI volumes and uses organ-independent imaging descriptions to constrain the semantic distribution of the visual modality. The above pre-training dataset is called Triad-131K, which is currently the largest 3D MRI pre-training dataset. We evaluate Triad across three tasks, namely, organ/tumor segmentation, organ/cancer classification, and medical image registration, in two data modalities (within-domain and out-of-domain) settings using 25 downstream datasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad improves segmentation performance by 2.51% compared to nnUNet-Scratch across 17 datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in classification tasks across five datasets. SwinUNETR-Triad improves by 4.00% compared to SwinUNETR-Scratch in registration tasks across two datasets. Our study demonstrates that pre-training can improve performance when the data modalities and organs of upstream and downstream tasks are consistent.","2025-02-23","2025-05-28 09:19:13","2025-05-28 09:19:14","2025-05-28 09:19:13","","","","","","","Triad","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.14064 [cs]","","/Users/alihaider/Zotero/storage/DW9YCHG8/Wang et al. - 2025 - Triad Vision Foundation Model for 3D Magnetic Resonance Imaging.pdf; /Users/alihaider/Zotero/storage/RNZYCZDR/2502.html","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2502.14064","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C7JYK2G7","preprint","2024","Jiang, Yufeng; Shen, Yiqing","M$^4$oE: A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts","","","","10.48550/arXiv.2405.09446","http://arxiv.org/abs/2405.09446","Medical imaging data is inherently heterogeneous across different modalities and clinical centers, posing unique challenges for developing generalizable foundation models. Conventional entails training distinct models per dataset or using a shared encoder with modality-specific decoders. However, these approaches incur heavy computational overheads and suffer from poor scalability. To address these limitations, we propose the Medical Multimodal Mixture of Experts (M$^4$oE) framework, leveraging the SwinUNet architecture. Specifically, M$^4$oE comprises modality-specific experts; each separately initialized to learn features encoding domain knowledge. Subsequently, a gating network is integrated during fine-tuning to modulate each expert's contribution to the collective predictions dynamically. This enhances model interpretability and generalization ability while retaining expertise specialization. Simultaneously, the M$^4$oE architecture amplifies the model's parallel processing capabilities, and it also ensures the model's adaptation to new modalities with ease. Experiments across three modalities reveal that M$^4$oE can achieve 3.45% over STU-Net-L, 5.11% over MED3D, and 11.93% over SAM-Med2D across the MICCAI FLARE22, AMOS2022, and ATLAS2023 datasets. Moreover, M$^4$oE showcases a significant reduction in training duration with 7 hours less while maintaining a parameter count that is only 30% of its compared methods. The code is available at https://github.com/JefferyJiang-YF/M4oE.","2024-05-15","2025-05-28 09:19:15","2025-05-28 09:19:15","2025-05-28 09:19:15","","","","","","","M$^4$oE","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2405.09446 [eess] version: 1","","/Users/alihaider/Zotero/storage/R8E7EP2F/Jiang and Shen - 2024 - M$^4$oE A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts.pdf; /Users/alihaider/Zotero/storage/ZYLG7FVG/2405.html","","","Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2405.09446","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7EMRWCY5","preprint","2023","Wu, Chaoyi; Zhang, Xiaoman; Zhang, Ya; Wang, Yanfeng; Xie, Weidi","Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D&3D Medical Data","","","","10.48550/arXiv.2308.02463","http://arxiv.org/abs/2308.02463","In this study, we aim to initiate the development of Radiology Foundation Model, termed as RadFM. We consider the construction of foundational models from three perspectives, namely, dataset construction, model design, and thorough evaluation. Our contribution can be concluded as follows: (i), we construct a large-scale Medical Multi-modal Dataset, MedMD, which consists of 16M 2D and 3D medical scans with high-quality text descriptions or reports across various data formats, modalities, and tasks, covering over 5000 distinct diseases. To the best of our knowledge, this is the first large-scale, high-quality, medical visual-language dataset, with both 2D and 3D scans; (ii), we propose an architecture that enables visually conditioned generative pre-training, i.e., allowing for integration of text input with 2D or 3D medical scans, and generate responses for diverse radiologic tasks. The model was initially pre-trained on MedMD and subsequently fine-tuned on the domain-specific dataset, which is a radiologic cleaned version of MedMD, containing 3M radiologic visual-language pairs, termed as RadMD; (iii), we propose a new evaluation benchmark, RadBench, that comprises five tasks, including modality recognition, disease diagnosis, visual question answering, report generation and rationale diagnosis, aiming to comprehensively assess the capability of foundation models in handling practical clinical problems. We conduct both automatic and human evaluation on RadBench, in both cases, RadFM outperforms existing multi-modal foundation models, that are publicaly accessible, including Openflamingo, MedFlamingo, MedVInT and GPT-4V. Additionally, we also adapt RadFM for different public benchmarks, surpassing existing SOTAs on diverse datasets. All codes, data, and model checkpoint will all be made publicly available to promote further research and development in the field.","2023-11-16","2025-05-28 09:19:58","2025-05-28 09:19:58","2025-05-28 09:19:58","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2308.02463 [cs]","","/Users/alihaider/Zotero/storage/SNR7VLRJ/Wu et al. - 2023 - Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D&3D Medical Data.pdf; /Users/alihaider/Zotero/storage/LKALGP5A/2308.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2308.02463","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y93IBW2H","journalArticle","2024","Ma, Jun; He, Yuting; Li, Feifei; Han, Lin; You, Chenyu; Wang, Bo","Segment Anything in Medical Images","Nature Communications","","2041-1723","10.1038/s41467-024-44824-z","http://arxiv.org/abs/2304.12306","Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans.","2024-01-22","2025-05-29 07:19:35","2025-05-29 07:19:35","2025-05-29 07:19:35","654","","1","15","","Nat Commun","","","","","","","","","","","","","arXiv.org","","arXiv:2304.12306 [eess]","","/Users/alihaider/Zotero/storage/MCIVIVTU/Ma et al. - 2024 - Segment Anything in Medical Images.pdf; /Users/alihaider/Zotero/storage/K42XGGCV/2304.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZ3PBNRZ","preprint","2022","Zhao, Ziheng; Zhang, Tianjiao; Xie, Weidi; Wang, Yanfeng; Zhang, Ya","K-Space Transformer for Undersampled MRI Reconstruction","","","","10.48550/arXiv.2206.06947","http://arxiv.org/abs/2206.06947","This paper considers the problem of undersampled MRI reconstruction. We propose a novel Transformer-based framework for directly processing signal in k-space, going beyond the limitation of regular grids as ConvNets do. We adopt an implicit representation of k-space spectrogram, treating spatial coordinates as inputs, and dynamically query the sparsely sampled points to reconstruct the spectrogram, i.e. learning the inductive bias in k-space. To strike a balance between computational cost and reconstruction quality, we build the decoder with hierarchical structure to generate low-resolution and high-resolution outputs respectively. To validate the effectiveness of our proposed method, we have conducted extensive experiments on two public datasets, and demonstrate superior or comparable performance to state-of-the-art approaches.","2022-11-10","2025-05-29 09:59:59","2025-05-29 09:59:59","2025-05-29 09:59:59","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2206.06947 [eess]","","/Users/alihaider/Zotero/storage/HKLNX732/Zhao et al. - 2022 - K-Space Transformer for Undersampled MRI Reconstruction.pdf; /Users/alihaider/Zotero/storage/YAXFWVTP/2206.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2206.06947","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVE2AKVN","preprint","2022","Zhou, Bo; Dey, Neel; Schlemper, Jo; Salehi, Seyed Sadegh Mohseni; Liu, Chi; Duncan, James S.; Sofka, Michal","DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction","","","","10.48550/arXiv.2201.10776","http://arxiv.org/abs/2201.10776","Multi-contrast MRI (MC-MRI) captures multiple complementary imaging modalities to aid in radiological decision-making. Given the need for lowering the time cost of multiple acquisitions, current deep accelerated MRI reconstruction networks focus on exploiting the redundancy between multiple contrasts. However, existing works are largely supervised with paired data and/or prohibitively expensive fully-sampled MRI sequences. Further, reconstruction networks typically rely on convolutional architectures which are limited in their capacity to model long-range interactions and may lead to suboptimal recovery of fine anatomical detail. To these ends, we present a dual-domain self-supervised transformer (DSFormer) for accelerated MC-MRI reconstruction. DSFormer develops a deep conditional cascade transformer (DCCT) consisting of several cascaded Swin transformer reconstruction networks (SwinRN) trained under two deep conditioning strategies to enable MC-MRI information sharing. We further present a dual-domain (image and k-space) self-supervised learning strategy for DCCT to alleviate the costs of acquiring fully sampled training data. DSFormer generates high-fidelity reconstructions which experimentally outperform current fully-supervised baselines. Moreover, we find that DSFormer achieves nearly the same performance when trained either with full supervision or with our proposed dual-domain self-supervision.","2022-08-17","2025-05-29 10:00:03","2025-05-29 10:00:03","2025-05-29 10:00:03","","","","","","","DSFormer","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2201.10776 [eess]","","/Users/alihaider/Zotero/storage/AJELGFHR/Zhou et al. - 2022 - DSFormer A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstructio.pdf; /Users/alihaider/Zotero/storage/6XWAYRXK/2201.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2201.10776","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZGJYGBP","preprint","2021","Zhao, Ruiyang; Yaman, Burhaneddin; Zhang, Yuxin; Stewart, Russell; Dixon, Austin; Knoll, Florian; Huang, Zhengnan; Lui, Yvonne W.; Hansen, Michael S.; Lungren, Matthew P.","fastMRI+: Clinical Pathology Annotations for Knee and Brain Fully Sampled Multi-Coil MRI Data","","","","10.48550/arXiv.2109.03812","http://arxiv.org/abs/2109.03812","Improving speed and image quality of Magnetic Resonance Imaging (MRI) via novel reconstruction approaches remains one of the highest impact applications for deep learning in medical imaging. The fastMRI dataset, unique in that it contains large volumes of raw MRI data, has enabled significant advances in accelerating MRI using deep learning-based reconstruction methods. While the impact of the fastMRI dataset on the field of medical imaging is unquestioned, the dataset currently lacks clinical expert pathology annotations, critical to addressing clinically relevant reconstruction frameworks and exploring important questions regarding rendering of specific pathology using such novel approaches. This work introduces fastMRI+, which consists of 16154 subspecialist expert bounding box annotations and 13 study-level labels for 22 different pathology categories on the fastMRI knee dataset, and 7570 subspecialist expert bounding box annotations and 643 study-level labels for 30 different pathology categories for the fastMRI brain dataset. The fastMRI+ dataset is open access and aims to support further research and advancement of medical imaging in MRI reconstruction and beyond.","2021-09-14","2025-09-17 04:07:55","2025-09-17 04:07:59","2025-09-17 04:07:55","","","","","","","fastMRI+","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2109.03812 [eess]","","/Users/alihaider/Zotero/storage/DLHLYJ83/Zhao et al. - 2021 - fastMRI+ Clinical Pathology Annotations for Knee and Brain Fully Sampled Multi-Coil MRI Data.pdf; /Users/alihaider/Zotero/storage/F78YP75W/2109.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning; Physics - Medical Physics","","","","","","","","","","","","","","","","","","","arXiv:2109.03812","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6I9A6J8","preprint","2025","Alam, Bashir; Cirkovic, Masa; Akcay, Mete Harun; Shahrier, Md Kaf; Lafond, Sebastien; Rexha, Hergys; Benke, Kurt; Azimi, Sepinoud; Arslan, Janan","CALF: A Conditionally Adaptive Loss Function to Mitigate Class-Imbalanced Segmentation","","","","10.48550/arXiv.2504.04458","http://arxiv.org/abs/2504.04458","Imbalanced datasets pose a considerable challenge in training deep learning (DL) models for medical diagnostics, particularly for segmentation tasks. Imbalance may be associated with annotation quality limited annotated datasets, rare cases, or small-scale regions of interest (ROIs). These conditions adversely affect model training and performance, leading to segmentation boundaries which deviate from the true ROIs. Traditional loss functions, such as Binary Cross Entropy, replicate annotation biases and limit model generalization. We propose a novel, statistically driven, conditionally adaptive loss function (CALF) tailored to accommodate the conditions of imbalanced datasets in DL training. It employs a data-driven methodology by estimating imbalance severity using statistical methods of skewness and kurtosis, then applies an appropriate transformation to balance the training dataset while preserving data heterogeneity. This transformative approach integrates a multifaceted process, encompassing preprocessing, dataset filtering, and dynamic loss selection to achieve optimal outcomes. We benchmark our method against conventional loss functions using qualitative and quantitative evaluations. Experiments using large-scale open-source datasets (i.e., UPENN-GBM, UCSF, LGG, and BraTS) validate our approach, demonstrating substantial segmentation improvements. Code availability: https://anonymous.4open.science/r/MICCAI-Submission-43F9/.","2025-04-06","2025-09-30 05:41:54","2025-09-30 05:41:59","2025-09-30 05:41:54","","","","","","","CALF","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.04458 [eess] version: 1","","/Users/alihaider/Zotero/storage/P342KA3W/Alam et al. - 2025 - CALF A Conditionally Adaptive Loss Function to Mitigate Class-Imbalanced Segmentation.pdf; /Users/alihaider/Zotero/storage/WUPUASJJ/2504.html","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2504.04458","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VW58CPVF","journalArticle","","Cheng, Jiacheng; Vasconcelos, Nuno","Towards Calibrated Multi-label Deep Neural Networks","","","","","","The problem of calibrating deep neural networks (DNNs) for multi-label learning is considered. It is wellknown that DNNs trained by cross-entropy for single-label, or one-hot, classification are poorly calibrated. Many calibration techniques have been proposed to address the problem. However, little attention has been paid to the calibration of multi-label DNNs. In this literature, the focus has been on improving labeling accuracy in the face of severe dataset unbalance. This is addressed by the introduction of asymmetric losses, which have became very popular. However, these losses do not induce well calibrated classifiers. In this work, we first provide a theoretical explanation for this poor calibration performance, by showing that these loses losses lack the strictly proper property, a necessary condition for accurate probability estimation. To overcome this problem, we propose a new Strictly Proper Asymmetric (SPA) loss. This is complemented by a Label Pair Regularizer (LPR) that increases the number of calibration constraints introduced per training example. The effectiveness of both contributions is validated by extensive experiments on various multi-label datasets. The resulting training method is shown to significantly decrease the calibration error while maintaining state-of-the-art accuracy.","","2025-09-30 05:56:16","2025-09-30 05:56:16","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/5XK6M86A/Cheng and Vasconcelos - Towards Calibrated Multi-label Deep Neural Networks.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""