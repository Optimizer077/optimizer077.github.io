<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Seminars â€“ Ali Haider</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: sans-serif;
      max-width: 800px;
      margin: auto;
      padding: 2rem;
      line-height: 1.6;
    }

    h1 {
      font-size: 2rem;
      margin-bottom: 0.5rem;
    }

    h2 {
      margin-top: 2.5rem;
      font-size: 1.4rem;
    }

    iframe {
      width: 100%;
      height: 480px;
      border: none;
      margin-top: 1rem;
      margin-bottom: 1.5rem;
    }

    a {
      color: #007acc;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .venue {
      color: #555;
      font-style: italic;
      margin-bottom: 1rem;
    }

    ul {
      padding-left: 1.2rem;
    }
  </style>
</head>
<body>

  <h1>ðŸ“¢ Seminar Talks</h1>
  <p class="venue">Presented at MLVC Lab, Kyung Hee University Global Campus</p>

  <section>
    <h2>Reasoning Models / Reasoning Image Restoration</h2>
    <p>
      A seminar covering the use of large language models and vision-language approaches in visual reasoning and restoration. We explored recent innovations in step-wise reasoning and multimodal agents for complex image tasks.
    </p>

    <iframe src="https://docs.google.com/presentation/d/1ju3ynd-XqNbtj0Pob5qd8oU2_5ithoQE/embed?start=false&loop=false&delayms=3000" allowfullscreen></iframe>

    <h3>Referenced Papers</h3>
    <ul>
      <li><a href="https://arxiv.org/abs/2404.07017" target="_blank">Improving Language Model Reasoning with Self-Motivated Learning</a></li>
      <li><a href="https://arxiv.org/abs/2407.18035" target="_blank">RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models</a></li>
      <li><a href="https://arxiv.org/abs/2410.08688" target="_blank">Chain-of-Restoration: Multi-Task Image Restoration Models as Zero-Shot Step-by-Step Universal Image Restorers</a></li>
    </ul>
  </section>

  <section>
    <h2>Multi-Task Learning Perspective for Diffusion Models</h2>
    <p>
      This seminar presents a multi-task learning viewpoint on modern diffusion models. It discusses task transferability, negative transfer challenges, and the use of mixture-of-experts to solve denoising in a synergistic fashion.
    </p>

    <iframe src="https://docs.google.com/presentation/d/1eyP_RBmBPBbr0TVzHAq4Lj7aFxSKbxw9/embed?start=false&loop=false&delayms=3000" allowfullscreen></iframe>

    <h3>Referenced Papers</h3>
    <ul>
      <li><a href="https://arxiv.org/abs/2306.00354" target="_blank">Addressing Negative Transfer in Diffusion Models</a></li>
      <li><a href="https://arxiv.org/abs/2403.09176" target="_blank">Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts</a></li>
    </ul>
  </section>

</body>
</html>
