"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"A44EVUU8","preprint","2024","Ekanayake, Mevan; Chen, Zhifeng; Egan, Gary; Harandi, Mehrtash; Chen, Zhaolin","SeCo-INR: Semantically Conditioned Implicit Neural Representations for Improved Medical Image Super-Resolution","","","","10.48550/arXiv.2409.01013","http://arxiv.org/abs/2409.01013","Implicit Neural Representations (INRs) have recently advanced the field of deep learning due to their ability to learn continuous representations of signals without the need for large training datasets. Although INR methods have been studied for medical image super-resolution, their adaptability to localized priors in medical images has not been extensively explored. Medical images contain rich anatomical divisions that could provide valuable local prior information to enhance the accuracy and robustness of INRs. In this work, we propose a novel framework, referred to as the Semantically Conditioned INR (SeCo-INR), that conditions an INR using local priors from a medical image, enabling accurate model fitting and interpolation capabilities to achieve super-resolution. Our framework learns a continuous representation of the semantic segmentation features of a medical image and utilizes it to derive the optimal INR for each semantic region of the image. We tested our framework using several medical imaging modalities and achieved higher quantitative scores and more realistic super-resolution outputs compared to state-of-the-art methods.","2024-09-02","2025-04-11 01:34:38","2025-04-11 01:34:38","2025-04-11 01:34:38","","","","","","","SeCo-INR","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2409.01013 [eess]","","/Users/alihaider/Zotero/storage/55DGEBJ5/Ekanayake et al. - 2024 - SeCo-INR Semantically Conditioned Implicit Neural Representations for Improved Medical Image Super-.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2409.01013","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NL952X2V","journalArticle","","Yang, Yiying; Yin, Fukun; Liu, Wen; Fan, Jiayuan; Chen, Xin; Yu, Gang; Chen, Tao","PM-INR: Prior-Rich Multi-Modal Implicit Large-Scale Scene Neural Representation","","","","","","Recent advancements in implicit neural representations have contributed to high-fidelity surface reconstruction and photorealistic novel view synthesis. However, with the expansion of the scene scale, such as block or city level, existing methods will encounter challenges because traditional sampling cannot cope with the cubically growing sampling space. To alleviate the dependence on filling the sampling space, we explore using multi-modal priors to assist individual points to obtain more global semantic information and propose a priorrich multi-modal implicit neural representation network, PMINR, for the outdoor unbounded large-scale scene. The core of our method is multi-modal prior extraction and crossmodal prior fusion modules. The former encodes codebooks from different modality inputs and extracts valuable priors, while the latter fuses priors to maintain view consistency and preserve unique features among multi-modal priors. Finally, feature-rich cross-modal priors are injected into the sampling regions to allow each region to perceive global information without filling the sampling space. Extensive experiments have demonstrated the effectiveness and robustness of our method for outdoor unbounded large-scale scene novel view synthesis, which outperforms state-of-the-art methods in terms of PSNR, SSIM, and LPIPS.","","2025-04-11 01:35:38","2025-04-11 01:35:38","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/A8X6H4DJ/Yang et al. - PM-INR Prior-Rich Multi-Modal Implicit Large-Scale Scene Neural Representation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBWCY6AS","preprint","2025","Kim, Jina; Lee, Jihoo; Kang, Je-Won","SNeRV: Spectra-preserving Neural Representation for Video","","","","10.1007/978-3-031-73001-6_19","http://arxiv.org/abs/2501.01681","Neural representation for video (NeRV), which employs a neural network to parameterize video signals, introduces a novel methodology in video representations. However, existing NeRV-based methods have difficulty in capturing fine spatial details and motion patterns due to spectral bias, in which a neural network learns high-frequency (HF) components at a slower rate than low-frequency (LF) components. In this paper, we propose spectra-preserving NeRV (SNeRV) as a novel approach to enhance implicit video representations by efficiently handling various frequency components. SNeRV uses 2D discrete wavelet transform (DWT) to decompose video into LF and HF features, preserving spatial structures and directly addressing the spectral bias issue. To balance the compactness, we encode only the LF components, while HF components that include fine textures are generated by a decoder. Specialized modules, including a multi-resolution fusion unit (MFU) and a high-frequency restorer (HFR), are integrated into a backbone to facilitate the representation. Furthermore, we extend SNeRV to effectively capture temporal correlations between adjacent video frames, by casting the extension as additional frequency decomposition to a temporal domain. This approach allows us to embed spatio-temporal LF features into the network, using temporally extended up-sampling blocks (TUBs). Experimental results demonstrate that SNeRV outperforms existing NeRV models in capturing fine details and achieves enhanced reconstruction, making it a promising approach in the field of implicit video representations. The codes are available at https://github.com/qwertja/SNeRV.","2025-01-03","2025-04-11 01:40:09","2025-04-11 01:40:09","2025-04-11 01:40:09","","","","","","","SNeRV","","","","","","","en","","","","","arXiv.org","","arXiv:2501.01681 [eess]","","/Users/alihaider/Zotero/storage/43X2GDL8/Kim et al. - 2025 - SNeRV Spectra-preserving Neural Representation for Video.pdf","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Q59ZCQC","preprint","2025","Byra, Michal; Skibbe, Henrik","Generating visual explanations from deep networks using implicit neural representations","","","","10.48550/arXiv.2501.11784","http://arxiv.org/abs/2501.11784","Explaining deep learning models in a way that humans can easily understand is essential for responsible artificial intelligence applications. Attribution methods constitute an important area of explainable deep learning. The attribution problem involves finding parts of the network’s input that are the most responsible for the model’s output. In this work, we demonstrate that implicit neural representations (INRs) constitute a good framework for generating visual explanations. Firstly, we utilize coordinate-based implicit networks to reformulate and extend the extremal perturbations technique and generate attribution masks. Experimental results confirm the usefulness of our method. For instance, by proper conditioning of the implicit network, we obtain attribution masks that are well-behaved with respect to the imposed area constraints. Secondly, we present an iterative INR-based method that can be used to generate multiple non-overlapping attribution masks for the same image. We depict that a deep learning model may associate the image label with both the appearance of the object of interest as well as with areas and textures usually accompanying the object. Our study demonstrates that implicit networks are well-suited for the generation of attribution masks and can provide interesting insights about the performance of deep learning models.","2025-01-20","2025-04-11 01:44:32","2025-04-11 01:44:32","2025-04-11 01:44:32","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2501.11784 [cs]","","/Users/alihaider/Zotero/storage/JSZTLIAG/Byra and Skibbe - 2025 - Generating visual explanations from deep networks using implicit neural representations.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2501.11784","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SK2A7U5G","journalArticle","","Khan, Asif Hussain; Micheloni, Christian; Martinel, Niki","IDENet: Implicit Degradation Estimation Network for Efficient Blind Super Resolution","","","","","","Blind image super-resolution (SR) aims to recover highresolution (HR) images from low-resolution (LR) inputs hindered by unknown degradation. Existing blind SR methods exploit computationally demanding explicit degradation estimators hinging on the availability of ground-truth information about the degradation process, thus introducing a severe limitation in real-world scenarios where this is inherently unattainable. Implicit degradation estimators avoid the need for ground truth but perform poorly. Our model reduces this performance gap with (i) a novel loss component to implicitly learn the degradation kernel from the LR input only, and (ii) a novel learnable Wiener filter module that exploits the learned degradation kernel to efficiently solve the deconvolution task via a closed-form solution formulated in the Fourier domain. Systematic experiments show that our proposed approach outperforms existing implicit blind SR methods (3dB PSNR gain and 8.5% SSIM improvement on average) and achieves comparable performance to explicit blind SR methods (0.6dB and 0.5% difference in PSNR and SSIM, respectively). Remarkably, these results are obtained using 33% and 71% less parameters than implicit and explicit methods.","","2025-04-11 01:45:39","2025-04-11 01:45:39","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/NVCV4X4X/Khan et al. - IDENet Implicit Degradation Estimation Network for Efficient Blind Super Resolution.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCINYM7Z","conferencePaper","2024","Chen, Chen; Liu, Daochang; Shah, Mubarak; Xu, Chang","Exploring Local Memorization in Diffusion Models via Bright Ending Attention","","","","","https://openreview.net/forum?id=p4cLtzk4oe&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2025%2FConference%2FAuthors%23your-submissions)","Text-to-image diffusion models have achieved unprecedented proficiency in generating realistic images. However, their inherent tendency to memorize and replicate training data during inference raises significant concerns, including potential copyright infringement. In response, various methods have been proposed to evaluate, detect, and mitigate memorization. Our analysis reveals that existing approaches significantly underperform in handling local memorization, where only specific image regions are memorized, compared to global memorization, where the entire image is replicated. Also, they cannot locate the local memorization regions, making it hard to investigate locally. To address these, we identify a novel ""bright ending"" (BE) anomaly in diffusion models prone to memorizing training images. BE refers to a distinct cross-attention pattern observed in text-to-image diffusion models, where memorized image patches exhibit significantly greater attention to the final text token during the last inference step than non-memorized patches. This pattern highlights regions where the generated image replicates training data and enables efficient localization of memorized regions. Equipped with this, we propose a simple yet effective method to integrate BE into existing frameworks, significantly improving their performance by narrowing the performance gap caused by local memorization. Our results not only validate the successful execution of the new localization task but also establish new state-of-the-art performance across all existing tasks, underscoring the significance of the BE phenomenon.","2024-10-04","2025-04-11 01:46:01","2025-04-11 01:46:01","2025-04-11 01:46:01","","","","","","","","","","","","","","en","","","","","openreview.net","","","","/Users/alihaider/Zotero/storage/P69YGW3A/Chen et al. - 2024 - Exploring Local Memorization in Diffusion Models via Bright Ending Attention.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The Thirteenth International Conference on Learning Representations","","","","","","","","","","","","","","",""
"YDYI38TX","preprint","2023","Kazerouni, Amirhossein; Azad, Reza; Hosseini, Alireza; Merhof, Dorit; Bagci, Ulas","INCODE: Implicit Neural Conditioning with Prior Knowledge Embeddings","","","","10.48550/arXiv.2310.18846","http://arxiv.org/abs/2310.18846","Implicit Neural Representations (INRs) have revolutionized signal representation by leveraging neural networks to provide continuous and smooth representations of complex data. However, existing INRs face limitations in capturing fine-grained details, handling noise, and adapting to diverse signal types. To address these challenges, we introduce INCODE, a novel approach that enhances the control of the sinusoidal-based activation function in INRs using deep prior knowledge. INCODE comprises a harmonizer network and a composer network, where the harmonizer network dynamically adjusts key parameters of the activation function. Through a task-specific pre-trained model, INCODE adapts the task-specific parameters to optimize the representation process. Our approach not only excels in representation, but also extends its prowess to tackle complex tasks such as audio, image, and 3D shape reconstructions, as well as intricate challenges such as neural radiance fields (NeRFs), and inverse problems, including denoising, super-resolution, inpainting, and CT reconstruction. Through comprehensive experiments, INCODE demonstrates its superiority in terms of robustness, accuracy, quality, and convergence rate, broadening the scope of signal representation. Please visit the project's website for details on the proposed method and access to the code.","2023-10-28","2025-04-11 01:49:03","2025-04-11 01:49:05","2025-04-11 01:49:03","","","","","","","INCODE","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2310.18846 [cs]","","/Users/alihaider/Zotero/storage/793HUKJV/Kazerouni et al. - 2023 - INCODE Implicit Neural Conditioning with Prior Knowledge Embeddings.pdf; /Users/alihaider/Zotero/storage/SV3SEM6R/2310.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2310.18846","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K36H3ID4","preprint","2024","Becker, Alexander; Daudt, Rodrigo Caye; Metzger, Nando; Wegner, Jan Dirk; Schindler, Konrad","Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution","","","","10.48550/arXiv.2311.17643","http://arxiv.org/abs/2311.17643","Recent approaches for arbitrary-scale single image super-resolution (ASSR) have used local neural fields to represent continuous signals that can be sampled at arbitrary rates. However, the point-wise query of the neural field does not naturally match the point spread function (PSF) of a given pixel, which may cause aliasing in the super-resolved image. We present a novel way to design neural fields such that points can be queried with an adaptive Gaussian PSF, so as to guarantee correct anti-aliasing at any desired output resolution. We achieve this with a novel activation function derived from Fourier theory. Querying points with a Gaussian PSF, compliant with sampling theory, does not incur any additional computational cost in our framework, unlike filtering in the image domain. With its theoretically guaranteed anti-aliasing, our method sets a new state of the art for ASSR, while being more parameter-efficient than previous methods. Notably, even a minimal version of our model still outperforms previous methods in most cases, while adding 2-4 orders of magnitude fewer parameters. Code and pretrained models are available at https://github.com/prs-eth/thera.","2024-03-14","2025-04-11 01:53:00","2025-04-11 01:53:01","2025-04-11 01:53:00","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2311.17643 [cs] version: 2","","/Users/alihaider/Zotero/storage/YK8QJGNC/Becker et al. - 2024 - Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution.pdf; /Users/alihaider/Zotero/storage/VCB7QE5A/2311.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2311.17643","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPH4KYIM","journalArticle","","Kovachki, Nikola; Li, Zongyi; Liu, Burigede; Azizzadenesheli, Kamyar; Bhattacharya, Kaushik; Stuart, Andrew","Neural Operator: Learning Maps Between Function Spaces With Applications to PDEs","","","","","","The classical development of neural networks has primarily focused on learning mappings between finite dimensional Euclidean spaces or finite sets. We propose a generalization of neural networks to learn operators, termed neural operators, that map between infinite dimensional function spaces. We formulate the neural operator as a composition of linear integral operators and nonlinear activation functions. We prove a universal approximation theorem for our proposed neural operator, showing that it can approximate any given nonlinear continuous operator. The proposed neural operators are also discretization-invariant, i.e., they share the same model parameters among different discretization of the underlying function spaces. Furthermore, we introduce four classes of efficient parameterization, viz., graph neural operators, multi-pole graph neural operators, lowrank neural operators, and Fourier neural operators. An important application for neural operators is learning surrogate maps for the solution operators of partial differential equations (PDEs). We consider standard PDEs such as the Burgers, Darcy subsurface flow, and the Navier-Stokes equations, and show that the proposed neural operators have superior performance compared to existing machine learning based methodologies, while being several orders of magnitude faster than conventional PDE solvers.","","2025-04-11 01:54:07","2025-04-11 01:54:08","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/397BF8FZ/Kovachki et al. - Neural Operator Learning Maps Between Function Spaces With Applications to PDEs.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRZH5NFJ","preprint","2023","Kwon, Sehyun; Choi, Joo Young; Ryu, Ernest K.","Rotation and Translation Invariant Representation Learning with Implicit Neural Representations","","","","10.48550/arXiv.2304.13995","http://arxiv.org/abs/2304.13995","In many computer vision applications, images are acquired with arbitrary or random rotations and translations, and in such setups, it is desirable to obtain semantic representations disentangled from the image orientation. Examples of such applications include semiconductor wafer defect inspection, plankton microscope images, and inference on single-particle cryo-electron microscopy (cryo-EM) micro-graphs. In this work, we propose Invariant Representation Learning with Implicit Neural Representation (IRL-INR), which uses an implicit neural representation (INR) with a hypernetwork to obtain semantic representations disentangled from the orientation of the image. We show that IRL-INR can effectively learn disentangled semantic representations on more complex images compared to those considered in prior works and show that these semantic representations synergize well with SCAN to produce state-of-the-art unsupervised clustering results.","2023-06-12","2025-04-11 01:54:18","2025-04-11 01:54:18","2025-04-11 01:54:18","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2304.13995 [cs]","","/Users/alihaider/Zotero/storage/U6VZ93JS/Kwon et al. - 2023 - Rotation and Translation Invariant Representation Learning with Implicit Neural Representations.pdf; /Users/alihaider/Zotero/storage/27BHY73D/2304.html","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2304.13995","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZDTH4VE","preprint","2023","Wei, Min; Zhang, Xuesong","Super-Resolution Neural Operator","","","","10.48550/arXiv.2303.02584","http://arxiv.org/abs/2303.02584","We propose Super-resolution Neural Operator (SRNO), a deep operator learning framework that can resolve high-resolution (HR) images at arbitrary scales from the low-resolution (LR) counterparts. Treating the LR-HR image pairs as continuous functions approximated with different grid sizes, SRNO learns the mapping between the corresponding function spaces. From the perspective of approximation theory, SRNO first embeds the LR input into a higher-dimensional latent representation space, trying to capture sufficient basis functions, and then iteratively approximates the implicit image function with a kernel integral mechanism, followed by a final dimensionality reduction step to generate the RGB representation at the target coordinates. The key characteristics distinguishing SRNO from prior continuous SR works are: 1) the kernel integral in each layer is efficiently implemented via the Galerkin-type attention, which possesses non-local properties in the spatial domain and therefore benefits the grid-free continuum; and 2) the multilayer attention architecture allows for the dynamic latent basis update, which is crucial for SR problems to ""hallucinate"" high-frequency information from the LR image. Experiments show that SRNO outperforms existing continuous SR methods in terms of both accuracy and running time. Our code is at https://github.com/2y7c3/Super-Resolution-Neural-Operator","2023-03-05","2025-04-11 01:56:09","2025-04-11 01:56:09","2025-04-11 01:56:09","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2303.02584 [cs]","","/Users/alihaider/Zotero/storage/H2SVXN4P/Wei and Zhang - 2023 - Super-Resolution Neural Operator.pdf; /Users/alihaider/Zotero/storage/C4XPCPN8/2303.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2303.02584","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5GHZYN8R","preprint","2024","Berman, Jules; Peherstorfer, Benjamin","CoLoRA: Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial differential equations","","","","10.48550/arXiv.2402.14646","http://arxiv.org/abs/2402.14646","This work introduces reduced models based on Continuous Low Rank Adaptation (CoLoRA) that pre-train neural networks for a given partial differential equation and then continuously adapt low-rank weights in time to rapidly predict the evolution of solution fields at new physics parameters and new initial conditions. The adaptation can be either purely data-driven or via an equation-driven variational approach that provides Galerkin-optimal approximations. Because CoLoRA approximates solution fields locally in time, the rank of the weights can be kept small, which means that only few training trajectories are required offline so that CoLoRA is well suited for data-scarce regimes. Predictions with CoLoRA are orders of magnitude faster than with classical methods and their accuracy and parameter efficiency is higher compared to other neural network approaches.","2024-07-21","2025-04-11 01:59:48","2025-04-11 01:59:54","2025-04-11 01:59:48","","","","","","","CoLoRA","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2402.14646 [cs]","","/Users/alihaider/Zotero/storage/2ETAZAU3/Berman and Peherstorfer - 2024 - CoLoRA Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial.pdf; /Users/alihaider/Zotero/storage/KZZCQ4AL/2402.html","","","Computer Science - Machine Learning; Computer Science - Numerical Analysis; Mathematics - Numerical Analysis; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2402.14646","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IU44TDLH","preprint","2024","Chen, Hanqiu; Yao, Xuebin; Subedi, Pradeep; Hao, Cong","Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation","","","","10.48550/arXiv.2408.05617","http://arxiv.org/abs/2408.05617","Edge computing is a distributed computing paradigm that collects and processes data at or near the source of data generation. The on-device learning at edge relies on device-to-device wireless communication to facilitate real-time data sharing and collaborative decision-making among multiple devices. This significantly improves the adaptability of the edge computing system to the changing environments. However, as the scale of the edge computing system is getting larger, communication among devices is becoming the bottleneck because of the limited bandwidth of wireless communication leads to large data transfer latency. To reduce the amount of device-to-device data transmission and accelerate on-device learning, in this paper, we propose Residual-INR, a fog computing-based communication-efficient on-device learning framework by utilizing implicit neural representation (INR) to compress images/videos into neural network weights. Residual-INR enhances data transfer efficiency by collecting JPEG images from edge devices, compressing them into INR format at the fog node, and redistributing them for on-device learning. By using a smaller INR for full image encoding and a separate object INR for high-quality object region reconstruction through residual encoding, our technique can reduce the encoding redundancy while maintaining the object quality. Residual-INR is a promising solution for edge on-device learning because it reduces data transmission by up to 5.16 x across a network of 10 edge devices. It also facilitates CPU-free accelerated on-device learning, achieving up to 2.9 x speedup without sacrificing accuracy. Our code is available at: https://github.com/sharc-lab/Residual-INR.","2024-12-16","2025-04-11 02:00:55","2025-04-11 02:00:57","2025-04-11 02:00:55","","","","","","","Residual-INR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2408.05617 [cs]","","/Users/alihaider/Zotero/storage/6ZAZJMTR/Chen et al. - 2024 - Residual-INR Communication Efficient On-Device Learning Using Implicit Neural Representation.pdf; /Users/alihaider/Zotero/storage/JCKGXIAC/2408.html","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning; Computer Science - Distributed, Parallel, and Cluster Computing; Computer Science - Information Theory; Mathematics - Information Theory","","","","","","","","","","","","","","","","","","","arXiv:2408.05617","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I4G9ME7T","preprint","2024","Li, Jason Chun Lok; Luo, Steven Tin Sui; Xu, Le; Wong, Ngai","ASMR: Activation-sharing Multi-resolution Coordinate Networks For Efficient Inference","","","","10.48550/arXiv.2405.12398","http://arxiv.org/abs/2405.12398","Coordinate network or implicit neural representation (INR) is a fast-emerging method for encoding natural signals (such as images and videos) with the benefits of a compact neural representation. While numerous methods have been proposed to increase the encoding capabilities of an INR, an often overlooked aspect is the inference efficiency, usually measured in multiply-accumulate (MAC) count. This is particularly critical in use cases where inference throughput is greatly limited by hardware constraints. To this end, we propose the Activation-Sharing Multi-Resolution (ASMR) coordinate network that combines multi-resolution coordinate decomposition with hierarchical modulations. Specifically, an ASMR model enables the sharing of activations across grids of the data. This largely decouples its inference cost from its depth which is directly correlated to its reconstruction capability, and renders a near O(1) inference complexity irrespective of the number of layers. Experiments show that ASMR can reduce the MAC of a vanilla SIREN model by up to 500x while achieving an even higher reconstruction quality than its SIREN baseline.","2024-05-20","2025-04-11 02:01:20","2025-04-11 02:01:20","2025-04-11 02:01:20","","","","","","","ASMR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2405.12398 [cs]","","/Users/alihaider/Zotero/storage/I8L9UYH5/Li et al. - 2024 - ASMR Activation-sharing Multi-resolution Coordinate Networks For Efficient Inference.pdf; /Users/alihaider/Zotero/storage/SEA9EAAG/2405.html","","","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2405.12398","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9L9RMS96","preprint","2025","Heidari, Moein; Rezaeian, Reza; Azad, Reza; Merhof, Dorit; Soltanian-Zadeh, Hamid; Hacihaliloglu, Ilker","SL$^{2}$A-INR: Single-Layer Learnable Activation for Implicit Neural Representation","","","","10.48550/arXiv.2409.10836","http://arxiv.org/abs/2409.10836","Implicit Neural Representation (INR), leveraging a neural network to transform coordinate input into corresponding attributes, has recently driven significant advances in several vision-related domains. However, the performance of INR is heavily influenced by the choice of the nonlinear activation function used in its multilayer perceptron (MLP) architecture. To date, multiple nonlinearities have been investigated, but current INRs still face limitations in capturing high-frequency components and diverse signal types. We show that these challenges can be alleviated by introducing a novel approach in INR architecture. Specifically, we propose SL$^{2}$A-INR, a hybrid network that combines a single-layer learnable activation function with an MLP that uses traditional ReLU activations. Our method performs superior across diverse tasks, including image representation, 3D shape reconstruction, and novel view synthesis. Through comprehensive experiments, SL$^{2}$A-INR sets new benchmarks in accuracy, quality, and robustness for INR. Our Code is publicly available on~\href{https://github.com/Iceage7/SL2A-INR}{\textcolor{magenta}{GitHub}}.","2025-03-21","2025-04-11 02:02:33","2025-04-11 02:02:35","2025-04-11 02:02:33","","","","","","","SL$^{2}$A-INR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2409.10836 [cs]","","/Users/alihaider/Zotero/storage/3HB9ZA9P/Heidari et al. - 2025 - SL$^{2}$A-INR Single-Layer Learnable Activation for Implicit Neural Representation.pdf; /Users/alihaider/Zotero/storage/55FDKLKU/2409.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2409.10836","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VXJTZ7X","preprint","2024","Zhao, Jiaming; Qiao, Wenbo; Zhang, Peng; Gao, Hui","Quantum Implicit Neural Representations","","","","10.48550/arXiv.2406.03873","http://arxiv.org/abs/2406.03873","Implicit neural representations have emerged as a powerful paradigm to represent signals such as images and sounds. This approach aims to utilize neural networks to parameterize the implicit function of the signal. However, when representing implicit functions, traditional neural networks such as ReLU-based multilayer perceptrons face challenges in accurately modeling high-frequency components of signals. Recent research has begun to explore the use of Fourier Neural Networks (FNNs) to overcome this limitation. In this paper, we propose Quantum Implicit Representation Network (QIREN), a novel quantum generalization of FNNs. Furthermore, through theoretical analysis, we demonstrate that QIREN possesses a quantum advantage over classical FNNs. Lastly, we conducted experiments in signal representation, image superresolution, and image generation tasks to show the superior performance of QIREN compared to state-of-the-art (SOTA) models. Our work not only incorporates quantum advantages into implicit neural representations but also uncovers a promising application direction for Quantum Neural Networks.","2024-09-01","2025-04-11 02:05:24","2025-04-11 02:05:25","2025-04-11 02:05:24","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2406.03873 [cs]","","/Users/alihaider/Zotero/storage/RN8X8U64/Zhao et al. - 2024 - Quantum Implicit Neural Representations.pdf; /Users/alihaider/Zotero/storage/NQYD8GBC/2406.html","","","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2406.03873","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TB6669R","preprint","2025","Essakine, Amer; Cheng, Yanqi; Cheng, Chun-Wun; Zhang, Lipei; Deng, Zhongying; Zhu, Lei; Schönlieb, Carola-Bibiane; Aviles-Rivero, Angelica I.","Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey","","","","10.48550/arXiv.2411.03688","http://arxiv.org/abs/2411.03688","Implicit Neural Representations (INRs) have emerged as a paradigm in knowledge representation, offering exceptional flexibility and performance across a diverse range of applications. INRs leverage multilayer perceptrons (MLPs) to model data as continuous implicit functions, providing critical advantages such as resolution independence, memory efficiency, and generalisation beyond discretised data structures. Their ability to solve complex inverse problems makes them particularly effective for tasks including audio reconstruction, image representation, 3D object reconstruction, and high-dimensional data synthesis. This survey provides a comprehensive review of state-of-the-art INR methods, introducing a clear taxonomy that categorises them into four key areas: activation functions, position encoding, combined strategies, and network structure optimisation. We rigorously analyse their critical properties, such as full differentiability, smoothness, compactness, and adaptability to varying resolutions while also examining their strengths and limitations in addressing locality biases and capturing fine details. Our experimental comparison offers new insights into the trade-offs between different approaches, showcasing the capabilities and challenges of the latest INR techniques across various tasks. In addition to identifying areas where current methods excel, we highlight key limitations and potential avenues for improvement, such as developing more expressive activation functions, enhancing positional encoding mechanisms, and improving scalability for complex, high-dimensional data. This survey serves as a roadmap for researchers, offering practical guidance for future exploration in the field of INRs. We aim to foster new methodologies by outlining promising research directions for INRs and applications.","2025-02-18","2025-04-11 02:05:51","2025-04-11 02:05:51","2025-04-11 02:05:51","","","","","","","Where Do We Stand with Implicit Neural Representations?","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2411.03688 [cs]","","/Users/alihaider/Zotero/storage/N2EK8LGZ/Essakine et al. - 2025 - Where Do We Stand with Implicit Neural Representations A Technical and Performance Survey.pdf; /Users/alihaider/Zotero/storage/RHNDAZKF/2411.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2411.03688","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCAS5Z6B","preprint","2022","Cho, Junwoo; Nam, Seungtae; Rho, Daniel; Ko, Jong Hwan; Park, Eunbyung","Streamable Neural Fields","","","","10.48550/arXiv.2207.09663","http://arxiv.org/abs/2207.09663","Neural fields have emerged as a new data representation paradigm and have shown remarkable success in various signal representations. Since they preserve signals in their network parameters, the data transfer by sending and receiving the entire model parameters prevents this emerging technology from being used in many practical scenarios. We propose streamable neural fields, a single model that consists of executable sub-networks of various widths. The proposed architectural and training techniques enable a single network to be streamable over time and reconstruct different qualities and parts of signals. For example, a smaller sub-network produces smooth and low-frequency signals, while a larger sub-network can represent fine details. Experimental results have shown the effectiveness of our method in various domains, such as 2D images, videos, and 3D signed distance functions. Finally, we demonstrate that our proposed method improves training stability, by exploiting parameter sharing.","2022-07-20","2025-04-11 02:09:23","2025-04-11 02:09:24","2025-04-11 02:09:23","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2207.09663 [cs]","","/Users/alihaider/Zotero/storage/6IWQA8PR/Cho et al. - 2022 - Streamable Neural Fields.pdf; /Users/alihaider/Zotero/storage/3WKCTVPV/2207.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2207.09663","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PH6Y76U9","conferencePaper","2024","Shabanov, Akhmedkhan Ahan; Govindarajan, Shrisudhan; Reading, Cody; Goli, Lily; Rebain, Daniel; Yi, Kwang Moo; Tagliasacchi, Andrea","BANF: Band-Limited Neural Fields for Levels of Detail Reconstruction","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","979-8-3503-5300-6","","10.1109/CVPR52733.2024.01944","https://ieeexplore.ieee.org/document/10658398/","","2024-06-16","2025-04-11 02:28:55","2025-04-11 02:28:55","2025-04-11 02:28:55","20571-20580","","","","","","BANF","","","","","IEEE","Seattle, WA, USA","en","https://doi.org/10.15223/policy-029","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/UEEZRKT4/Shabanov et al. - 2024 - BANF Band-Limited Neural Fields for Levels of Detail Reconstruction.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","","","","","","","","","","","","","","",""
"SDXECZ2Z","preprint","2023","Bauer, Matthias; Dupont, Emilien; Brock, Andy; Rosenbaum, Dan; Schwarz, Jonathan Richard; Kim, Hyunjik","Spatial Functa: Scaling Functa to ImageNet Classification and Generation","","","","10.48550/arXiv.2302.03130","http://arxiv.org/abs/2302.03130","Neural fields, also known as implicit neural representations, have emerged as a powerful means to represent complex signals of various modalities. Based on this Dupont et al. (2022) introduce a framework that views neural fields as data, termed *functa*, and proposes to do deep learning directly on this dataset of neural fields. In this work, we show that the proposed framework faces limitations when scaling up to even moderately complex datasets such as CIFAR-10. We then propose *spatial functa*, which overcome these limitations by using spatially arranged latent representations of neural fields, thereby allowing us to scale up the approach to ImageNet-1k at 256x256 resolution. We demonstrate competitive performance to Vision Transformers (Steiner et al., 2022) on classification and Latent Diffusion (Rombach et al., 2022) on image generation respectively.","2023-02-09","2025-04-11 02:29:01","2025-04-11 02:29:01","2025-04-11 02:29:00","","","","","","","Spatial Functa","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2302.03130 [cs]","","/Users/alihaider/Zotero/storage/ECZQ7L5A/Bauer et al. - 2023 - Spatial Functa Scaling Functa to ImageNet Classification and Generation.pdf; /Users/alihaider/Zotero/storage/YVPMMPTF/2302.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2302.03130","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CV2XCCNT","preprint","2024","Cai, Zhicheng","Conv-INR: Convolutional Implicit Neural Representation for Multimodal Visual Signals","","","","10.48550/arXiv.2406.04249","http://arxiv.org/abs/2406.04249","Implicit neural representation (INR) has recently emerged as a promising paradigm for signal representations. Typically, INR is parameterized by a multiplayer perceptron (MLP) which takes the coordinates as the inputs and generates corresponding attributes of a signal. However, MLP-based INRs face two critical issues: i) individually considering each coordinate while ignoring the connections; ii) suffering from the spectral bias thus failing to learn high-frequency components. While target visual signals usually exhibit strong local structures and neighborhood dependencies, and high-frequency components are significant in these signals, the issues harm the representational capacity of INRs. This paper proposes Conv-INR, the first INR model fully based on convolution. Due to the inherent attributes of convolution, Conv-INR can simultaneously consider adjacent coordinates and learn high-frequency components effectively. Compared to existing MLP-based INRs, Conv-INR has better representational capacity and trainability without requiring primary function expansion. We conduct extensive experiments on four tasks, including image fitting, CT/MRI reconstruction, and novel view synthesis, Conv-INR all significantly surpasses existing MLP-based INRs, validating the effectiveness. Finally, we raise three reparameterization methods that can further enhance the performance of the vanilla Conv-INR without introducing any extra inference cost.","2024-06-06","2025-04-11 02:29:17","2025-04-11 02:29:17","2025-04-11 02:29:17","","","","","","","Conv-INR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2406.04249 [cs]","","/Users/alihaider/Zotero/storage/RCGMXJTN/Cai - 2024 - Conv-INR Convolutional Implicit Neural Representation for Multimodal Visual Signals.pdf; /Users/alihaider/Zotero/storage/ST5WPJCK/2406.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2406.04249","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ZPJAF9A","preprint","2020","Sanokowski, Sebastian","Implicit recurrent networks: A novel approach to stationary input processing with recurrent neural networks in deep learning","","","","10.48550/arXiv.2010.10564","http://arxiv.org/abs/2010.10564","The brain cortex, which processes visual, auditory and sensory data in the brain, is known to have many recurrent connections within its layers and from higher to lower layers. But, in the case of machine learning with neural networks, it is generally assumed that strict feed-forward architectures are suitable for static input data, such as images, whereas recurrent networks are required mainly for the processing of sequential input, such as language. However, it is not clear whether also processing of static input data benefits from recurrent connectivity. In this work, we introduce and test a novel implementation of recurrent neural networks with lateral and feed-back connections into deep learning. This departure from the strict feed-forward structure prevents the use of the standard error backpropagation algorithm for training the networks. Therefore we provide an algorithm which implements the backpropagation algorithm on a implicit implementation of recurrent networks, which is different from state-of-the-art implementations of recurrent neural networks. Our method, in contrast to current recurrent neural networks, eliminates the use of long chains of derivatives due to many iterative update steps, which makes learning computationally less costly. It turns out that the presence of recurrent intra-layer connections within a one-layer implicit recurrent network enhances the performance of neural networks considerably: A single-layer implicit recurrent network is able to solve the XOR problem, while a feed-forward network with monotonically increasing activation function fails at this task. Finally, we demonstrate that a two-layer implicit recurrent architecture leads to a better performance in a regression task of physical parameters from the measured trajectory of a damped pendulum.","2020-10-20","2025-04-11 02:29:40","2025-04-11 02:29:40","2025-04-11 02:29:40","","","","","","","Implicit recurrent networks","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2010.10564 [cs]","","/Users/alihaider/Zotero/storage/WBDUM694/Sanokowski - 2020 - Implicit recurrent networks A novel approach to stationary input processing with recurrent neural n.pdf; /Users/alihaider/Zotero/storage/VWIQGQCY/2010.html","","","Computer Science - Machine Learning; Computer Science - Neural and Evolutionary Computing","","","","","","","","","","","","","","","","","","","arXiv:2010.10564","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RK35UWHM","conferencePaper","2021","Huang, Zhichun; Bai, Shaojie; Kolter, J. Zico","(\textbackslash textrmłbrace Implicit\rbrace )^2: Implicit Layers for Implicit Representations","Advances in Neural Information Processing Systems","","","","https://proceedings.neurips.cc/paper_files/paper/2021/hash/4ffbd5c8221d7c147f8363ccdc9a2a37-Abstract.html","","2021","2025-04-11 02:29:54","2025-04-11 02:29:54","2025-04-11 02:29:54","9639–9650","","","34","","","(\textbackslash textrmłbrace Implicit\rbrace )^2","","","","","Curran Associates, Inc.","","","","","","","Neural Information Processing Systems","","","","/Users/alihaider/Zotero/storage/3ZNQQI8B/Huang et al. - 2021 - (textbackslash textrmłbrace Implicitrbrace )^2 Implicit Layers for Implicit Representations.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PKL47M36","preprint","2024","Delbracio, Mauricio; Milanfar, Peyman","Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration","","","","10.48550/arXiv.2303.11435","http://arxiv.org/abs/2303.11435","Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called “regression to the mean” effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.","2024-02-02","2025-04-11 02:37:54","2025-04-11 02:37:54","2025-04-11 02:37:54","","","","","","","Inversion by Direct Iteration","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2303.11435 [eess]","","/Users/alihaider/Zotero/storage/M35JBDFP/Delbracio and Milanfar - 2024 - Inversion by Direct Iteration An Alternative to Denoising Diffusion for Image Restoration.pdf","","","Computer Science - Computer Vision and Pattern Recognition; Electrical Engineering and Systems Science - Image and Video Processing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2303.11435","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPGDDDX7","journalArticle","","Hao, Zekun; Mallya, Arun; Belongie, Serge; Liu, Ming-Yu","Implicit Neural Representations with Levels-of-Experts","","","","","","Coordinate-based networks, usually in the forms of MLPs, have been successfully applied to the task of predicting high-frequency but low-dimensional signals using coordinate inputs. To scale them to model large-scale signals, previous works resort to hybrid representations, combining a coordinate-based network with a grid-based representation, such as sparse voxels. However, such approaches lack a compact global latent representation in its grid, making it difficult to model a distribution of signals, which is important for generalization tasks. To address the limitation, we propose the Levels-of-Experts (LoE) framework, which is a novel coordinate-based representation consisting of an MLP with periodic, positiondependent weights arranged hierarchically. For each linear layer of the MLP, multiple candidate values of its weight matrix are tiled and replicated across the input space, with different layers replicating at different frequencies. Based on the input, only one of the weight matrices is chosen for each layer. This greatly increases the model capacity without incurring extra computation or compromising generalization capability. We show that the new representation is an efficient and competitive drop-in replacement for a wide range of tasks, including signal fitting, novel view synthesis, and generative modeling.","","2025-04-11 02:37:55","2025-04-11 02:37:55","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/7P6XB7M5/Hao et al. - Implicit Neural Representations with Levels-of-Experts.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJLHGRHW","preprint","2024","Ben-Shabat, Yizhak; Koneputugodage, Chamin Hewa; Ramasinghe, Sameera; Gould, Stephen","Neural Experts: Mixture of Experts for Implicit Neural Representations","","","","10.48550/arXiv.2410.21643","http://arxiv.org/abs/2410.21643","Implicit neural representations (INRs) have proven effective in various tasks including image, shape, audio, and video reconstruction. These INRs typically learn the implicit field from sampled input points. This is often done using a single network for the entire domain, imposing many global constraints on a single function. In this paper, we propose a mixture of experts (MoE) implicit neural representation approach that enables learning local piece-wise continuous functions that simultaneously learns to subdivide the domain and fit it locally. We show that incorporating a mixture of experts architecture into existing INR formulations provides a boost in speed, accuracy, and memory requirements. Additionally, we introduce novel conditioning and pretraining methods for the gating network that improves convergence to the desired solution. We evaluate the effectiveness of our approach on multiple reconstruction tasks, including surface reconstruction, image reconstruction, and audio signal reconstruction and show improved performance compared to non-MoE methods. Code is available at our project page https://sitzikbs.github.io/neural-experts-projectpage/.","2024-10-29","2025-04-11 02:37:57","2025-04-11 02:37:57","2025-04-11 02:37:57","","","","","","","Neural Experts","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2410.21643 [cs]","","/Users/alihaider/Zotero/storage/LULBPIR9/Ben-Shabat et al. - 2024 - Neural Experts Mixture of Experts for Implicit Neural Representations.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2410.21643","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3E95IAC","preprint","2024","Zhang, Shuyi; Liu, Ke; Gu, Jingjun; Cai, Xiaoxu; Wang, Zhihua; Bu, Jiajun; Wang, Haishuai","Attention Beats Linear for Fast Implicit Neural Representation Generation","","","","10.48550/arXiv.2407.15355","http://arxiv.org/abs/2407.15355","Implicit Neural Representation (INR) has gained increasing popularity as a data representation method, serving as a prerequisite for innovative generation models. Unlike gradient-based methods, which exhibit lower efficiency in inference, the adoption of hyper-network for generating parameters in Multi-Layer Perceptrons (MLP), responsible for executing INR functions, has surfaced as a promising and efficient alternative. However, as a global continuous function, MLP is challenging in modeling highly discontinuous signals, resulting in slow convergence during the training phase and inaccurate reconstruction performance. Moreover, MLP requires massive representation parameters, which implies inefficiencies in data representation. In this paper, we propose a novel Attention-based Localized INR (ANR) composed of a localized attention layer (LAL) and a global MLP that integrates coordinate features with data features and converts them to meaningful outputs. Subsequently, we design an instance representation framework that delivers a transformer-like hyper-network to represent data instances as a compact representation vector. With instance-specific representation vector and instance-agnostic ANR parameters, the target signals are well reconstructed as a continuous function. We further address aliasing artifacts with variational coordinates when obtaining the super-resolution inference results. Extensive experimentation across four datasets showcases the notable efficacy of our ANR method, e.g. enhancing the PSNR value from 37.95dB to 47.25dB on the CelebA dataset. Code is released at https://github.com/Roninton/ANR.","2024-07-22","2025-04-11 02:37:59","2025-04-11 02:37:59","2025-04-11 02:37:59","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2407.15355 [cs]","","/Users/alihaider/Zotero/storage/I4ZS9YFM/Zhang et al. - 2024 - Attention Beats Linear for Fast Implicit Neural Representation Generation.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2407.15355","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Z8TE3VX","preprint","2024","Gao, Rui; Jaiman, Rajeev K.","H-SIREN: Improving implicit neural representations with hyperbolic periodic functions","","","","10.48550/arXiv.2410.04716","http://arxiv.org/abs/2410.04716","Implicit neural representations (INR) have been recently adopted in various applications ranging from computer vision tasks to physics simulations by solving partial differential equations. Among existing INR-based works, multi-layer perceptrons with sinusoidal activation functions find widespread applications and are also frequently treated as a baseline for the development of better activation functions for INR applications. Recent investigations claim that the use of sinusoidal activation functions could be sub-optimal due to their limited supported frequency set as well as their tendency to generate over-smoothed solutions. We provide a simple solution to mitigate such an issue by changing the activation function at the first layer from sin(x) to sin(sinh(2x)). We demonstrate H-SIREN in various computer vision and fluid flow problems, where it surpasses the performance of several state-of-the-art INRs.","2024-10-07","2025-04-11 02:38:00","2025-04-11 02:38:00","2025-04-11 02:38:00","","","","","","","H-SIREN","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2410.04716 [cs]","","/Users/alihaider/Zotero/storage/G4I6CLB4/Gao and Jaiman - 2024 - H-SIREN Improving implicit neural representations with hyperbolic periodic functions.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2410.04716","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHVZ65VQ","preprint","2024","Padmanabhan, Namitha; Gwilliam, Matthew; Kumar, Pulkit; Maiya, Shishira R.; Ehrlich, Max; Shrivastava, Abhinav","Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions","","","","10.48550/arXiv.2401.10217","http://arxiv.org/abs/2401.10217","The many variations of Implicit Neural Representations (INRs), where a neural network is trained as a continuous representation of a signal, have tremendous practical utility for downstream tasks including novel view synthesis, video compression, and image superresolution. Unfortunately, the inner workings of these networks are seriously under-studied. Our work, eXplaining the Implicit Neural Canvas (XINC), is a unified framework for explaining properties of INRs by examining the strength of each neuron’s contribution to each output pixel. We call the aggregate of these contribution maps the Implicit Neural Canvas and we use this concept to demonstrate that the INRs which we study learn to “see” the frames they represent in surprising ways. For example, INRs tend to have highly distributed representations. While lacking high-level object semantics, they have a significant bias for color and edges, and are almost entirely space-agnostic. We arrive at our conclusions by examining how objects are represented across time in video INRs, using clustering to visualize similar neurons across layers and architectures, and show that this is dominated by motion. These insights demonstrate the general usefulness of our analysis framework. Our project page is available here.","2024-07-16","2025-04-11 02:38:02","2025-04-11 02:38:03","2025-04-11 02:38:02","","","","","","","Explaining the Implicit Neural Canvas","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2401.10217 [cs]","","/Users/alihaider/Zotero/storage/NI2C6748/Padmanabhan et al. - 2024 - Explaining the Implicit Neural Canvas Connecting Pixels to Neurons by Tracing their Contributions.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2401.10217","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8B4PZL2","preprint","2025","Mehrabian, Ali; Adi, Parsa Mojarad; Heidari, Moein; Hacihaliloglu, Ilker","Implicit Neural Representations with Fourier Kolmogorov-Arnold Networks","","","","10.48550/arXiv.2409.09323","http://arxiv.org/abs/2409.09323","Implicit neural representations (INRs) use neural networks to provide continuous and resolution-independent representations of complex signals with a small number of parameters. However, existing INR models often fail to capture important frequency components specific to each task. To address this issue, in this paper, we propose a Fourier Kolmogorov–Arnold network (FKAN) for INRs. The proposed FKAN utilizes learnable activation functions modeled as Fourier series in the first layer to effectively control and learn the task-specific frequency components. In addition, the activation functions with learnable Fourier coefficients improve the ability of the network to capture complex patterns and details, which is beneficial for high-resolution and high-dimensional data. Experimental results show that our proposed FKAN model outperforms three state-ofthe-art baseline schemes, and improves the peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) for the image representation task and intersection over union (IoU) for the 3D occupancy volume representation task, respectively.","2025-01-14","2025-04-11 02:38:05","2025-04-11 02:38:05","2025-04-11 02:38:05","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2409.09323 [cs]","","/Users/alihaider/Zotero/storage/AI8H2Z76/Mehrabian et al. - 2025 - Implicit Neural Representations with Fourier Kolmogorov-Arnold Networks.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2409.09323","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WURX7KD2","preprint","2023","Wang, Peng; Liu, Yuan; Chen, Zhaoxi; Liu, Lingjie; Liu, Ziwei; Komura, Taku; Theobalt, Christian; Wang, Wenping","F$^{2}$-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories","","","","10.48550/arXiv.2303.15951","http://arxiv.org/abs/2303.15951","This paper presents a novel grid-based NeRF called F2NeRF (Fast-Free-NeRF) for novel view synthesis, which enables arbitrary input camera trajectories and only costs a few minutes for training. Existing fast grid-based NeRF training frameworks, like Instant-NGP, Plenoxels, DVGO, or TensoRF, are mainly designed for bounded scenes and rely on space warping to handle unbounded scenes. Existing two widely-used space-warping methods are only designed for the forward-facing trajectory or the 360◦ object-centric trajectory but cannot process arbitrary trajectories. In this paper, we delve deep into the mechanism of space warping to handle unbounded scenes. Based on our analysis, we further propose a novel space-warping method called perspective warping, which allows us to handle arbitrary trajectories in the grid-based NeRF framework. Extensive experiments demonstrate that F2-NeRF is able to use the same perspective warping to render high-quality images on two standard datasets and a new free trajectory dataset collected by us. Project page: https:// totoro97.github.io/ projects/ f2-nerf .","2023-03-28","2025-04-11 02:38:08","2025-04-11 02:38:08","2025-04-11 02:38:08","","","","","","","F$^{2}$-NeRF","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2303.15951 [cs]","","/Users/alihaider/Zotero/storage/W8ANE54T/Wang et al. - 2023 - F$^{2}$-NeRF Fast Neural Radiance Field Training with Free Camera Trajectories.pdf","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2303.15951","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DW25CHEH","preprint","2023","Liu, Zhen; Zhu, Hao; Zhang, Qi; Fu, Jingde; Deng, Weibing; Ma, Zhan; Guo, Yanwen; Cao, Xun","FINER: Flexible spectral-bias tuning in Implicit NEural Representation by Variable-periodic Activation Functions","","","","10.48550/arXiv.2312.02434","http://arxiv.org/abs/2312.02434","Implicit Neural Representation (INR), which utilizes a neural network to map coordinate inputs to corresponding attributes, is causing a revolution in the field of signal processing. However, current INR techniques suffer from a restricted capability to tune their supported frequency set, resulting in imperfect performance when representing complex signals with multiple frequencies. We have identified that this frequency-related problem can be greatly alleviated by introducing variable-periodic activation functions, for which we propose FINER. By initializing the bias of the neural network within different ranges, sub-functions with various frequencies in the variable-periodic function are selected for activation. Consequently, the supported frequency set of FINER can be flexibly tuned, leading to improved performance in signal representation. We demonstrate the capabilities of FINER in the contexts of 2D image fitting, 3D signed distance field representation, and 5D neural radiance fields optimization, and we show that it outperforms existing INRs.","2023-12-05","2025-04-11 02:38:10","2025-04-11 02:38:10","2025-04-11 02:38:10","","","","","","","FINER","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2312.02434 [cs]","","/Users/alihaider/Zotero/storage/HMZQIZW3/Liu et al. - 2023 - FINER Flexible spectral-bias tuning in Implicit NEural Representation by Variable-periodic Activati.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2312.02434","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CY43D2IA","journalArticle","","Kim, Chiheon; Lee, Doyup; Kim, Saehoon; Cho, Minsu; Han, Wook-Shin","Generalizable Implicit Neural Representations via Instance Pattern Composers","","","","","","Despite recent advances in implicit neural representations (INRs), it remains challenging for a coordinate-based multi-layer perceptron (MLP) of INRs to learn a common representation across data instances and generalize it for unseen instances. In this work, we introduce a simple yet effective framework for generalizable INRs that enables a coordinate-based MLP to represent complex data instances by modulating only a small set of weights in an early MLP layer as an instance pattern composer; the remaining MLP weights learn pattern composition rules for common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in learning to predict the modulated weight for unseen instances. Extensive experiments demonstrate that our method achieves high performance on a wide range of domains such as an audio, image, and 3D object, while the ablation study validates our weight modulation.","","2025-04-11 02:38:17","2025-04-11 02:38:17","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/MCTGTZC9/Kim et al. - Generalizable Implicit Neural Representations via Instance Pattern Composers.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F3IZNYJQ","conferencePaper","2023","Li, Zhemin; Wang, Hongxia; Meng, Deyu","Regularize implicit neural representation by itself","2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","979-8-3503-0129-8","","10.1109/CVPR52729.2023.00991","https://ieeexplore.ieee.org/document/10204036/","This paper proposes a regularizer called Implicit Neural Representation Regularizer (INRR) to improve the generalization ability of the Implicit Neural Representation (INR). The INR is a fully connected network that can represent signals with details not restricted by grid resolution. However, its generalization ability could be improved, especially with non-uniformly sampled data. The proposed INRR is based on learned Dirichlet Energy (DE) that measures similarities between rows/columns of the matrix. The smoothness of the Laplacian matrix is further integrated by parameterizing DE with a tiny INR. INRR improves the generalization of INR in signal representation by perfectly integrating the signal’s self-similarity with the smoothness of the Laplacian matrix. Through well-designed numerical experiments, the paper also reveals a series of properties derived from INRR, including momentum methods like convergence trajectory and multi-scale similarity. Moreover, the proposed method could improve the performance of other signal representation methods.","2023-06","2025-04-11 02:38:25","2025-04-11 02:38:25","2025-04-11 02:38:25","10280-10288","","","","","","","","","","","IEEE","Vancouver, BC, Canada","en","https://doi.org/10.15223/policy-029","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/TH2T46QX/Li et al. - 2023 - Regularize implicit neural representation by itself.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","","","","","","","","","","","","","","",""
"FTIWVNTJ","journalArticle","","Vyas, Kushal; Humayun, Ahmed Imtiaz; Dashpute, Aniket; Baraniuk, Richard G; Veeraraghavan, Ashok; Balakrishnan, Guha","Learning Transferable Features for Implicit Neural Representations","","","","","","Implicit neural representations (INRs) have demonstrated success in a variety of applications, including inverse problems and neural rendering. An INR is typically trained to capture one signal of interest, resulting in learned neural features that are highly attuned to that signal. Assumed to be less generalizable, we explore the aspect of transferability of such learned neural features for fitting similar signals. We introduce a new INR training framework, STRAINER that learns transferrable features for fitting INRs to new signals from a given distribution, faster and with better reconstruction quality. Owing to the sequential layer-wise affine operations in an INR, we propose to learn transferable representations by sharing initial encoder layers across multiple INRs with independent decoder layers. At test time, the learned encoder representations are transferred as initialization for an otherwise randomly initialized INR. We find STRAINER to yield extremely powerful initialization for fitting images from the same domain and allow for a ≈ +10dB gain in signal quality early on compared to an untrained INR itself. STRAINER also provides a simple way to encode data-driven priors in INRs. We evaluate STRAINER on multiple in-domain and out-of-domain signal fitting tasks and inverse problems and further provide detailed analysis and discussion on the transferability of STRAINER’s features. Our demo can be accessed here.","","2025-04-11 02:49:41","2025-04-11 02:49:41","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/ZIP6JNMM/Vyas et al. - Learning Transferable Features for Implicit Neural Representations.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MMT95IM","preprint","2024","Cai, Zhicheng; Shen, Qiu","Encoding Semantic Priors into the Weights of Implicit Neural Representation","","","","10.48550/arXiv.2406.04178","http://arxiv.org/abs/2406.04178","Implicit neural representation (INR) has recently emerged as a promising paradigm for signal representations, which takes coordinates as inputs and generates corresponding signal values. Since these coordinates contain no semantic features, INR fails to take any semantic information into consideration. However, semantic information has been proven critical in many vision tasks, especially for visual signal representation. This paper proposes a reparameterization method termed as SPW, which encodes the semantic priors to the weights of INR, thus making INR contain semantic information implicitly and enhancing its representational capacity. Specifically, SPW uses the Semantic Neural Network (SNN) to extract both low- and high-level semantic information of the target visual signal and generates the semantic vector, which is input into the Weight Generation Network (WGN) to generate the weights of INR model. Finally, INR uses the generated weights with semantic priors to map the coordinates to the signal values. After training, we only retain the generated weights while abandoning both SNN and WGN, thus SPW introduces no extra costs in inference. Experimental results show that SPW can improve the performance of various INR models significantly on various tasks, including image fitting, CT reconstruction, MRI reconstruction, and novel view synthesis. Further experiments illustrate that model with SPW has lower weight redundancy and learns more novel representations, validating the effectiveness of SPW.","2024-06-06","2025-04-14 08:35:08","2025-04-14 08:35:11","2025-04-14 08:35:08","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2406.04178 [cs]","","/Users/alihaider/Zotero/storage/K9HUCAZV/Cai and Shen - 2024 - Encoding Semantic Priors into the Weights of Implicit Neural Representation.pdf; /Users/alihaider/Zotero/storage/H7WWCXJ9/2406.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2406.04178","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LU7RE54","conferencePaper","2024","Chen, Xiang; Pan, Jinshan; Dong, Jiangxin","Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","979-8-3503-5300-6","","10.1109/CVPR52733.2024.02421","https://ieeexplore.ieee.org/document/10658243/","How to effectively explore multi-scale representations of rain streaks is important for image deraining. In contrast to existing Transformer-based methods that depend mostly on single-scale rain appearance, we develop an end-to-end multi-scale Transformer that leverages the potentially useful features in various scales to facilitate high-quality image reconstruction. To better explore the common degradation representations from spatially-varying rain streaks, we incorporate intra-scale implicit neural representations based on pixel coordinates with the degraded inputs in a closed-loop design, enabling the learned features to facilitate rain removal and improve the robustness of the model in complex scenarios. To ensure richer collaborative representation from different scales, we embed a simple yet effective inter-scale bidirectional feedback operation into our multi-scale Transformer by performing coarse-to-ﬁne and ﬁne-to-coarse information communication. Extensive experiments demonstrate that our approach, named as NeRDRain, performs favorably against the state-of-the-art ones on both synthetic and real-world benchmark datasets. The source code and trained models are available at https: //github.com/cschenxiang/NeRD-Rain.","2024-06-16","2025-04-14 08:45:07","2025-04-14 08:45:07","2025-04-14 08:45:07","25627-25636","","","","","","","","","","","IEEE","Seattle, WA, USA","en","https://doi.org/10.15223/policy-029","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/9A33WSEC/Chen et al. - 2024 - Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","","","","","","","","","","","","","","",""
"5YR92NML","preprint","2024","Gupta, Vinayak; S, Manoj; T, Mukund Varma; Mitra, Kaushik","U2NeRF: Unsupervised Underwater Image Restoration and Neural Radiance Fields","","","","10.48550/arXiv.2411.16172","http://arxiv.org/abs/2411.16172","Underwater images suffer from colour shifts, low contrast, and haziness due to light absorption, refraction, scattering and restoring these images has warranted much attention. In this work, we present Unsupervised Underwater Neural Radiance Field U2NeRF, a transformer-based architecture that learns to render and restore novel views conditioned on multi-view geometry simultaneously. Due to the absence of supervision, we attempt to implicitly bake restoring capabilities onto the NeRF pipeline and disentangle the predicted color into several components - scene radiance, direct transmission map, backscatter transmission map, and global background light, and when combined reconstruct the underwater image in a self-supervised manner. In addition, we release an Underwater View Synthesis UVS dataset consisting of 12 underwater scenes, containing both synthetically-generated and real-world data. Our experiments demonstrate that when optimized on a single scene, U2NeRF outperforms several baselines by as much LPIPS 11%, UIQM 5%, UCIQE 4% (on average) and showcases improved rendering and restoration capabilities. Code will be made available upon acceptance.","2024-11-25","2025-04-14 08:47:45","2025-04-14 08:47:45","2025-04-14 08:47:45","","","","","","","U2NeRF","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2411.16172 [cs]","","/Users/alihaider/Zotero/storage/T95V8D5D/Gupta et al. - 2024 - U2NeRF Unsupervised Underwater Image Restoration and Neural Radiance Fields.pdf; /Users/alihaider/Zotero/storage/GBZNCKLH/2411.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2411.16172","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YR93JKSP","preprint","2024","Zhang, Chen; Luo, Steven Tin Sui; Li, Jason Chun Lok; Wu, Yik-Chung; Wong, Ngai","Nonparametric Teaching of Implicit Neural Representations","","","","10.48550/arXiv.2405.10531","http://arxiv.org/abs/2405.10531","We investigate the learning of implicit neural representation (INR) using an overparameterized multilayer perceptron (MLP) via a novel nonparametric teaching perspective. The latter offers an efficient example selection framework for teaching nonparametrically defined (viz. non-closed-form) target functions, such as image functions defined by 2D grids of pixels. To address the costly training of INRs, we propose a paradigm called Implicit Neural Teaching (INT) that treats INR learning as a nonparametric teaching problem, where the given signal being fitted serves as the target function. The teacher then selects signal fragments for iterative training of the MLP to achieve fast convergence. By establishing a connection between MLP evolution through parameter-based gradient descent and that of function evolution through functional gradient descent in nonparametric teaching, we show for the first time that teaching an overparameterized MLP is consistent with teaching a nonparametric learner. This new discovery readily permits a convenient drop-in of nonparametric teaching algorithms to broadly enhance INR training efficiency, demonstrating 30%+ training time savings across various input modalities.","2024-05-17","2025-04-15 02:05:12","2025-04-15 02:05:12","2025-04-15 02:05:12","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2405.10531 [cs]","","/Users/alihaider/Zotero/storage/W8MJXTXB/Zhang et al. - 2024 - Nonparametric Teaching of Implicit Neural Representations.pdf; /Users/alihaider/Zotero/storage/6V5T9428/2405.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2405.10531","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K88X32YP","journalArticle","","Shi, Kexuan; Zhou, Xingyu; Gu, Shuhang","Improved Implicit Neural Representation with Fourier Reparameterized Training","","","","","","Implicit Neural Representation (INR) as a mighty representation paradigm has achieved success in various computer vision tasks recently. Due to the low-frequency bias issue of vanilla multi-layer perceptron (MLP), existing methods have investigated advanced techniques, such as positional encoding and periodic activation function, to improve the accuracy of INR. In this paper, we connect the network training bias with the reparameterization technique and theoretically prove that weight reparameterization could provide us a chance to alleviate the spectral bias of MLP. Based on our theoretical analysis, we propose a Fourier reparameterization method which learns coefficient matrix of fixed Fourier bases to compose the weights of MLP. We evaluate the proposed Fourier reparameterization method on different INR tasks with various MLP architectures, including vanilla MLP, MLP with positional encoding and MLP with advanced activation function, etc. The superiority approximation results on different MLP architectures clearly validate the advantage of our proposed method. Armed with our Fourier reparameterization method, better INR with more textures and less artifacts can be learned from the training data. The codes are available at https: //github.com/LabShuHangGU/FR-INR.","","2025-04-16 02:08:37","2025-04-16 02:08:37","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/JDS84IID/Shi et al. - Improved Implicit Neural Representation with Fourier Reparameterized Training.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NAZZSJ2R","journalArticle","2024","Czerkawski, Mikolaj; Cardona, Javier; Atkinson, Robert; Michie, Craig; Andonovic, Ivan; Clemente, Carmine; Tachtatzis, Christos","Neural Knitworks: Patched neural implicit representation networks","Pattern Recognition","","00313203","10.1016/j.patcog.2024.110378","https://linkinghub.elsevier.com/retrieve/pii/S0031320324001298","Optimizing images as output of a neural network has been shown to introduce a powerful prior for image inverse tasks, capable of producing solutions of reasonable quality in a fully internal learning context, where no external datasets are involved. Two potential technical approaches involve fitting a coordinate-based Multilayer Perceptron (MLP), or a Convolutional Neural Network to produce the result image as output. The aim of this work is to evaluate the two counterparts, as well as a new framework proposed here, named Neural Knitwork, which maps pixel coordinates to local texture patches rather than singular pixel values. The utility of the proposed technique is demonstrated on the tasks of image inpainting, super-resolution, and denoising. It is shown that the Neural Knitwork can outperform the standard coordinate-based MLP baseline for the tasks of inpainting and denoising, and perform comparably for the super-resolution task.","2024-07","2025-04-22 03:49:21","2025-04-22 03:49:21","2025-04-22 03:49:21","110378","","","151","","Pattern Recognition","Neural Knitworks","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/2R5HDVHJ/Czerkawski et al. - 2024 - Neural Knitworks Patched neural implicit representation networks.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"339KNXUY","preprint","2025","Zhang, Weixiang; Xie, Shuzhao; Ren, Chengwei; Xie, Siyi; Tang, Chen; Ge, Shijia; Wang, Mingzi; Wang, Zhi","EVOS: Efficient Implicit Neural Training via EVOlutionary Selector","","","","10.48550/arXiv.2412.10153","http://arxiv.org/abs/2412.10153","We propose EVOlutionary Selector (EVOS), an efficient training paradigm for accelerating Implicit Neural Representation (INR). Unlike conventional INR training that feeds all samples through the neural network in each iteration, our approach restricts training to strategically selected points, reducing computational overhead by eliminating redundant forward passes. Specifically, we treat each sample as an individual in an evolutionary process, where only those fittest ones survive and merit inclusion in training, adaptively evolving with the neural network dynamics. While this is conceptually similar to Evolutionary Algorithms, their distinct objectives (selection for acceleration vs. iterative solution optimization) require a fundamental redefinition of evolutionary mechanisms for our context. In response, we design sparse fitness evaluation, frequency-guided crossover, and augmented unbiased mutation to comprise EVOS. These components respectively guide sample selection with reduced computational cost, enhance performance through frequency-domain balance, and mitigate selection bias from cached evaluation. Extensive experiments demonstrate that our method achieves approximately 48%-66% reduction in training time while ensuring superior convergence without additional cost, establishing state-of-the-art acceleration among recent sampling-based strategies.","2025-04-04","2025-04-23 08:10:59","2025-04-23 08:11:00","2025-04-23 08:10:59","","","","","","","EVOS","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2412.10153 [cs]","","/Users/alihaider/Zotero/storage/VSMIGIWU/Zhang et al. - 2025 - EVOS Efficient Implicit Neural Training via EVOlutionary Selector.pdf; /Users/alihaider/Zotero/storage/8TPIP2FL/2412.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Neural and Evolutionary Computing; Computer Science - Multimedia","","","","","","","","","","","","","","","","","","","arXiv:2412.10153","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VI34NYWB","conferencePaper","2024","Catania, Lorenzo; Allegra, Dario","Redefining Visual Quality: The Impact of Loss Functions on INR-Based Image Compression","2024 IEEE International Conference on Image Processing (ICIP)","979-8-3503-4939-9","","10.1109/ICIP51287.2024.10647328","https://ieeexplore.ieee.org/document/10647328/","Implicit Neural Representations (INR) are a novel data representation technique which is gaining ground in the image compression field due to its simplicity and interesting results in terms of rate/distortion ratio. Although a variety of methods based on this paradigm were proposed, limited interest has been given to the analysis of the loss function and the impact of compression artifacts on the visual quality of the reconstructed images, which are mainly due to the adoption of the simple Mean Squared Error (MSE) loss function and to the evaluation done merely in terms of Peak Signal-to-Noise Ratio (PSNR), which do not often correlate with the human perception. In this paper, we evaluate a set of five loss functions in the context of training INRs for image compression, applied to three state-of-the-art architectures, and evaluate their effect on a broader collection of quantitative metrics and the visual fidelity of the decoded images to the originals. The presented outcomes show that the reconstructions obtained by training with some loss functions as MSE suffer from over-smoothing and aliasing artifacts. Our findings reveal that through the employing of a suitable loss function, state-of-the-art architectures quantitatively and qualitatively outperform the results reported in their original papers.","2024-10-27","2025-04-28 05:47:48","2025-04-28 05:47:48","2025-04-28 05:47:48","1973-1979","","","","","","Redefining Visual Quality","","","","","IEEE","Abu Dhabi, United Arab Emirates","en","https://doi.org/10.15223/policy-029","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/I5VQ42AY/Catania and Allegra - 2024 - Redefining Visual Quality The Impact of Loss Functions on INR-Based Image Compression.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 IEEE International Conference on Image Processing (ICIP)","","","","","","","","","","","","","","",""
"BEQF8UH3","preprint","2025","Zhang, Weixiang; Xie, Shuzhao; Ren, Chengwei; Ge, Shijia; Wang, Mingzi; Wang, Zhi","Enhancing Implicit Neural Representations via Symmetric Power Transformation","","","","10.48550/arXiv.2412.09213","http://arxiv.org/abs/2412.09213","We propose symmetric power transformation to enhance the capacity of Implicit Neural Representation~(INR) from the perspective of data transformation. Unlike prior work utilizing random permutation or index rearrangement, our method features a reversible operation that does not require additional storage consumption. Specifically, we first investigate the characteristics of data that can benefit the training of INR, proposing the Range-Defined Symmetric Hypothesis, which posits that specific range and symmetry can improve the expressive ability of INR. Based on this hypothesis, we propose a nonlinear symmetric power transformation to achieve both range-defined and symmetric properties simultaneously. We use the power coefficient to redistribute data to approximate symmetry within the target range. To improve the robustness of the transformation, we further design deviation-aware calibration and adaptive soft boundary to address issues of extreme deviation boosting and continuity breaking. Extensive experiments are conducted to verify the performance of the proposed method, demonstrating that our transformation can reliably improve INR compared with other data transformations. We also conduct 1D audio, 2D image and 3D video fitting tasks to demonstrate the effectiveness and applicability of our method.","2025-04-02","2025-04-28 05:54:28","2025-04-28 05:54:28","2025-04-28 05:54:28","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2412.09213 [cs]","","/Users/alihaider/Zotero/storage/86TLBT62/Zhang et al. - 2025 - Enhancing Implicit Neural Representations via Symmetric Power Transformation.pdf; /Users/alihaider/Zotero/storage/VTZ7BHML/2412.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2412.09213","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZRA6PDX","preprint","2025","Haider, Ali; Ali, Muhammad Salman; Qamar, Maryam; Khalil, Tahir; Kim, Soo Ye; Oh, Jihyong; Tartaglione, Enzo; Bae, Sung-Ho","I-INR: Iterative Implicit Neural Representations","","","","10.48550/arXiv.2504.17364","http://arxiv.org/abs/2504.17364","Implicit Neural Representations (INRs) have revolutionized signal processing and computer vision by modeling signals as continuous, differentiable functions parameterized by neural networks. However, their inherent formulation as a regression problem makes them prone to regression to the mean, limiting their ability to capture fine details, retain high-frequency information, and handle noise effectively. To address these challenges, we propose Iterative Implicit Neural Representations (I-INRs) a novel plugand-play framework that enhances signal reconstruction through an iterative refinement process. I-INRs effectively recover high-frequency details, improve robustness to noise, and achieve superior reconstruction quality. Our framework seamlessly integrates with existing INR architectures, delivering substantial performance gains across various tasks. Extensive experiments show that I-INRs outperform baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision applications such as image restoration, image denoising, and object occupancy prediction.","2025-04-24","2025-05-12 10:20:55","2025-05-12 10:20:55","2025-05-12 10:20:55","","","","","","","I-INR","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2504.17364 [cs]","","/Users/alihaider/Zotero/storage/LA4LTC34/Haider et al. - 2025 - I-INR Iterative Implicit Neural Representations.pdf","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2504.17364","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCK2BZ6G","preprint","2025","Han, Woo Kyoung; Lee, Byeonghun; Cho, Hyunmin; Im, Sunghoon; Jin, Kyong Hwan","Towards Lossless Implicit Neural Representation via Bit Plane Decomposition","","","","10.48550/arXiv.2502.21001","http://arxiv.org/abs/2502.21001","We quantify the upper bound on the size of the implicit neural representation (INR) model from a digital perspective. The upper bound of the model size increases exponentially as the required bit-precision increases. To this end, we present a bit-plane decomposition method that makes INR predict bit-planes, producing the same effect as reducing the upper bound of the model size. We validate our hypothesis that reducing the upper bound leads to faster convergence with constant model size. Our method achieves lossless representation in 2D image and audio fitting, even for high bit-depth signals, such as 16-bit, which was previously unachievable. We pioneered the presence of bit bias, which INR prioritizes as the most significant bit (MSB). We expand the application of the INR task to bit depth expansion, lossless image compression, and extreme network quantization. Our source code is available at https://github.com/WooKyoungHan/LosslessINR","2025-03-20","2025-05-20 07:25:57","2025-05-20 07:26:01","2025-05-20 07:25:57","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.21001 [cs]","","/Users/alihaider/Zotero/storage/NVFTCPHM/Han et al. - 2025 - Towards Lossless Implicit Neural Representation via Bit Plane Decomposition.pdf; /Users/alihaider/Zotero/storage/U3VQM9T2/2502.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2502.21001","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZQF4PMM","conferencePaper","2024","Thamizharasan, Vikas; Liu, Difan; Fisher, Matthew; Zhao, Nanxuan; Kalogerakis, Evangelos; Lukáč, Michal","NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","979-8-3503-5300-6","","10.1109/CVPR52733.2024.00439","https://ieeexplore.ieee.org/document/10657860/","The success of denoising diffusion models in representing rich data distributions over 2D raster images has prompted research on extending them to other data representations, such as vector graphics. Unfortunately due to their variable structure and scarcity of vector training data, directly applying diffusion models on this domain remains a challenging problem. Using workarounds like optimization via Score Distillation Sampling (SDS) is also fraught with difficulty, as vector representations are non-trivial to directly optimize and tend to result in implausible geometries such as redundant or self-intersecting shapes. NIVeL addresses these challenges by reinterpreting the problem on an alternative, intermediate domain which preserves the desirable properties of vector graphics – mainly sparsity of representation and resolution-independence. This alternative domain is based on neural implicit fields expressed in a set of decomposable, editable layers. Based on our experiments, NIVeL produces text-to-vector graphics results of significantly better quality than the state-of-the-art.","2024-06-16","2025-05-23 06:27:51","2025-05-23 06:27:51","2025-05-23 06:27:51","4589-4597","","","","","","NIVeL","","","","","IEEE","Seattle, WA, USA","en","https://doi.org/10.15223/policy-029","","","","DOI.org (Crossref)","","","","/Users/alihaider/Zotero/storage/QRL92FLT/Thamizharasan et al. - 2024 - NIVeL Neural Implicit Vector Layers for Text-to-Vector Generation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","","","","","","","","","","","","","","",""
"IRYXZASQ","journalArticle","","Amaduzzi, Andrea; Ramirez, Pierluigi Zama; Lisanti, Giuseppe; Salti, Samuele","LLaNA: Large Language and NeRF Assistant","","","","","","Multimodal Large Language Models (MLLMs) have demonstrated an excellent understanding of images and 3D data. However, both modalities have shortcomings in holistically capturing the appearance and geometry of objects. Meanwhile, Neural Radiance Fields (NeRFs), which encode information within the weights of a simple Multi-Layer Perceptron (MLP), have emerged as an increasingly widespread modality that simultaneously encodes the geometry and photorealistic appearance of objects. This paper investigates the feasibility and effectiveness of ingesting NeRF into MLLM. We create LLaNA, the first general-purpose NeRFlanguage assistant capable of performing new tasks such as NeRF captioning and Q&A. Notably, our method directly processes the weights of the NeRF’s MLP to extract information about the represented objects without the need to render images or materialize 3D data structures. Moreover, we build a dataset of NeRFs with text annotations for various NeRF-language tasks with no human intervention. Based on this dataset, we develop a benchmark to evaluate the NeRF understanding capability of our method. Results show that processing NeRF weights performs favourably against extracting 2D or 3D representations from NeRFs.","","2025-05-23 06:28:02","2025-05-23 06:28:03","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/Users/alihaider/Zotero/storage/W9C7ZLDE/Amaduzzi et al. - LLaNA Large Language and NeRF Assistant.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V43VL8QN","preprint","2025","Cheng, Yanqi; Zeng, Tieyong; Lio, Pietro; Schönlieb, Carola-Bibiane; Aviles-Rivero, Angelica I.","Deep Spectral Prior","","","","10.48550/arXiv.2505.19873","http://arxiv.org/abs/2505.19873","We introduce Deep Spectral Prior (DSP), a new formulation of Deep Image Prior (DIP) that redefines image reconstruction as a frequency-domain alignment problem. Unlike traditional DIP, which relies on pixel-wise loss and early stopping to mitigate overfitting, DSP directly matches Fourier coefficients between the network output and observed measurements. This shift introduces an explicit inductive bias towards spectral coherence, aligning with the known frequency structure of images and the spectral bias of convolutional neural networks. We provide a rigorous theoretical framework demonstrating that DSP acts as an implicit spectral regulariser, suppressing high-frequency noise by design and eliminating the need for early stopping. Our analysis spans four core dimensions establishing smooth convergence dynamics, local stability, and favourable bias-variance tradeoffs. We further show that DSP naturally projects reconstructions onto a frequency-consistent manifold, enhancing interpretability and robustness. These theoretical guarantees are supported by empirical results across denoising, inpainting, and super-resolution tasks, where DSP consistently outperforms classical DIP and other unsupervised baselines.","2025-05-26","2025-07-02 09:41:39","2025-07-02 09:41:39","2025-07-02 09:41:39","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2505.19873 [cs]","","/Users/alihaider/Zotero/storage/4V2SYZQU/Cheng et al. - 2025 - Deep Spectral Prior.pdf; /Users/alihaider/Zotero/storage/YTYG2JW4/2505.html","","","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Numerical Analysis; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2505.19873","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBK4YUKR","webpage","","","Iterative_INR_AAAI_2025","","","","","https://www.overleaf.com/project/6867243c914a887416720d9d","An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.","","2025-07-15 05:27:07","2025-07-15 05:27:07","2025-07-15 05:27:07","","","","","","","","","","","","","","en","","","","","","","","","/Users/alihaider/Zotero/storage/UVIFAP82/6867243c914a887416720d9d.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8QW6LYJ","preprint","2023","Zhang, Chulong; Liang, Xiaokun","INR-LDDMM: Fluid-based Medical Image Registration Integrating Implicit Neural Representation and Large Deformation Diffeomorphic Metric Mapping","","","","10.48550/arXiv.2308.09473","http://arxiv.org/abs/2308.09473","We propose a fluid-based registration framework of medical images based on implicit neural representation. By integrating implicit neural representation and Large Deformable Diffeomorphic Metric Mapping (LDDMM), we employ a Multilayer Perceptron (MLP) as a velocity generator while optimizing velocity and image similarity. Moreover, we adopt a coarse-to-fine approach to address the challenge of deformable-based registration methods dropping into local optimal solutions, thus aiding the management of significant deformations in medical image registration. Our algorithm has been validated on a paired CT-CBCT dataset of 50 patients,taking the Dice coefficient of transferred annotations as an evaluation metric. Compared to existing methods, our approach achieves the state-of-the-art performance.","2023-11-27","2025-08-25 04:36:35","2025-08-25 04:36:37","2025-08-25 04:36:35","","","","","","","INR-LDDMM","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2308.09473 [eess]","","/Users/alihaider/Zotero/storage/IKNLZAGM/Zhang and Liang - 2023 - INR-LDDMM Fluid-based Medical Image Registration Integrating Implicit Neural Representation and Lar.pdf; /Users/alihaider/Zotero/storage/DD33R8D9/2308.html","","","Electrical Engineering and Systems Science - Image and Video Processing","","","","","","","","","","","","","","","","","","","arXiv:2308.09473","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P7X5W3S","preprint","2025","Kayabasi, Alper; Vadathya, Anil Kumar; Balakrishnan, Guha; Saragadam, Vishwanath","Bias for Action: Video Implicit Neural Representations with Bias Modulation","","","","10.48550/arXiv.2501.09277","http://arxiv.org/abs/2501.09277","We propose a new continuous video modeling framework based on implicit neural representations (INRs) called ActINR. At the core of our approach is the observation that INRs can be considered as a learnable dictionary, with the shapes of the basis functions governed by the weights of the INR, and their locations governed by the biases. Given compact non-linear activation functions, we hypothesize that an INR's biases are suitable to capture motion across images, and facilitate compact representations for video sequences. Using these observations, we design ActINR to share INR weights across frames of a video sequence, while using unique biases for each frame. We further model the biases as the output of a separate INR conditioned on time index to promote smoothness. By training the video INR and this bias INR together, we demonstrate unique capabilities, including $10\times$ video slow motion, 4x spatial super resolution along with 2x slow motion, denoising, and video inpainting. ActINR performs remarkably well across numerous video processing tasks (often achieving more than 6dB improvement), setting a new standard for continuous modeling of videos.","2025-06-06","2025-09-26 04:56:02","2025-09-26 04:56:08","2025-09-26 04:56:02","","","","","","","Bias for Action","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2501.09277 [cs]","","/Users/alihaider/Zotero/storage/22PRZWMN/Kayabasi et al. - 2025 - Bias for Action Video Implicit Neural Representations with Bias Modulation.pdf; /Users/alihaider/Zotero/storage/FW6UFBG4/2501.html","","","Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2501.09277","","","","","","","","","","","","","","","","","","","","","","","","","","",""